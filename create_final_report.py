#!/usr/bin/env python3
"""
Script para criar relat√≥rio final consolidado com todos os datasets corrigidos
"""

import pandas as pd
import os
from datetime import datetime

def create_final_consolidated_report():
    """Cria relat√≥rio final consolidado com todos os datasets corrigidos"""
    
    # Buscar arquivos de an√°lise corrigidos
    files = {
        'Instagram': None,
        'TikTok': None,
        'YouTube': None
    }
    
    # Buscar arquivos mais recentes
    for platform in files.keys():
        pattern = f"ANALISE_{platform.upper()}_CORRIGIDO_"
        matching_files = [f for f in os.listdir('out') if f.startswith(pattern)]
        if matching_files:
            files[platform] = sorted(matching_files)[-1]
    
    print("üìä Criando relat√≥rio final consolidado...")
    print("üì± Arquivos encontrados:")
    for platform, file in files.items():
        if file:
            print(f"   - {platform.upper()}: {file}")
        else:
            print(f"   - {platform.upper()}: ‚ùå N√£o encontrado")
    
    # Carregar dados
    data = {}
    
    for platform, file in files.items():
        if file:
            try:
                df = pd.read_csv(f"out/{file}")
                data[platform] = df
                print(f"‚úÖ {platform}: {len(df):,} coment√°rios carregados")
            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao carregar {platform}: {str(e)}")
    
    if not data:
        print("‚ùå Nenhum dado foi carregado com sucesso!")
        return
    
    # Consolidar todos os dados
    all_data = []
    for platform, df in data.items():
        all_data.append(df)
    
    consolidated_df = pd.concat(all_data, ignore_index=True)
    
    # Salvar relat√≥rio consolidado
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    consolidated_file = f"out/RELATORIO_FINAL_CONSOLIDADO_CORRIGIDO_{timestamp}.csv"
    consolidated_df.to_csv(consolidated_file, index=False, encoding='utf-8')
    
    print(f"üíæ Relat√≥rio consolidado salvo: {consolidated_file}")
    
    # Estat√≠sticas gerais
    total_all = len(consolidated_df)
    hate_all = len(consolidated_df[consolidated_df['predicted_label'] == 'HATE'])
    nao_hate_all = len(consolidated_df[consolidated_df['predicted_label'] == 'N√ÉO-HATE'])
    
    print(f"\nüåê ESTAT√çSTICAS GERAIS (TODAS AS PLATAFORMAS):")
    print(f"   - Total de coment√°rios: {total_all:,}")
    print(f"   - Coment√°rios HATE: {hate_all:,} ({hate_all/total_all*100:.1f}%)")
    print(f"   - Coment√°rios N√ÉO-HATE: {nao_hate_all:,} ({nao_hate_all/total_all*100:.1f}%)")
    
    # Estat√≠sticas por plataforma
    print(f"\nüì± ESTAT√çSTICAS POR PLATAFORMA:")
    for platform in ['Instagram', 'TikTok', 'YouTube']:
        if platform in data:
            platform_df = consolidated_df[consolidated_df['platform'] == platform]
            platform_hate = len(platform_df[platform_df['predicted_label'] == 'HATE'])
            platform_total = len(platform_df)
            print(f"   - {platform}: {platform_hate:,}/{platform_total:,} ({platform_hate/platform_total*100:.1f}% HATE)")
    
    # Distribui√ß√£o por m√©todo geral
    print(f"\nüîß TOP M√âTODOS DE DETEC√á√ÉO (GERAL):")
    method_counts = consolidated_df['method'].value_counts()
    for method, count in method_counts.head(10).items():
        print(f"   - {method}: {count:,} ({count/total_all*100:.1f}%)")
    
    # Distribui√ß√£o por classe especializada (HATE)
    hate_df = consolidated_df[consolidated_df['predicted_label'] == 'HATE']
    if len(hate_df) > 0:
        print(f"\nüéØ DISTRIBUI√á√ÉO POR CLASSE ESPECIALIZADA (HATE):")
        class_counts = hate_df['specialized_class'].value_counts()
        for class_name, count in class_counts.items():
            if class_name != 'N/A':
                print(f"   - {class_name}: {count:,} ({count/len(hate_df)*100:.1f}%)")
    
    # Compara√ß√£o com resultados anteriores
    print(f"\nüìà COMPARA√á√ÉO COM RESULTADOS ANTERIORES:")
    print(f"   ANTES das corre√ß√µes:")
    print(f"   - Total: 12,102 coment√°rios")
    print(f"   - HATE: 5,627 (46.5%)")
    print(f"   - N√ÉO-HATE: 6,475 (53.5%)")
    print(f"")
    print(f"   DEPOIS das corre√ß√µes:")
    print(f"   - Total: {total_all:,} coment√°rios")
    print(f"   - HATE: {hate_all:,} ({hate_all/total_all*100:.1f}%)")
    print(f"   - N√ÉO-HATE: {nao_hate_all:,} ({nao_hate_all/total_all*100:.1f}%)")
    print(f"")
    print(f"   MELHORIA:")
    print(f"   - Redu√ß√£o de HATE: {5627 - hate_all:,} casos ({5627 - hate_all:.1f}%)")
    print(f"   - Aumento de N√ÉO-HATE: {nao_hate_all - 6475:,} casos ({nao_hate_all - 6475:.1f}%)")
    
    return consolidated_file

if __name__ == "__main__":
    print("üöÄ Iniciando cria√ß√£o do relat√≥rio final consolidado...")
    output_file = create_final_consolidated_report()
    if output_file:
        print(f"‚úÖ Relat√≥rio final criado com sucesso! Arquivo: {output_file}")
    else:
        print("‚ùå Falha na cria√ß√£o do relat√≥rio final")
