#!/usr/bin/env python3
"""
An√°lise usando APENAS o sistema do Space (sem valida√ß√£o adicional)
Para comparar com a vers√£o com redund√¢ncia
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime
import re

# Adicionar o diret√≥rio atual ao path
sys.path.append('.')

# Importar as fun√ß√µes do sistema
from app_space_version import predict_hate_speech

def analyze_with_space_only(df_final):
    """An√°lise usando APENAS o sistema do Space"""
    print("üîç AN√ÅLISE USANDO APENAS O SISTEMA DO SPACE")
    print("=" * 50)
    
    results = []
    total_examples = len(df_final)
    
    for idx, row in df_final.iterrows():
        if idx % 100 == 0:
            print(f"üìà Progresso: {idx}/{total_examples} ({idx/total_examples*100:.1f}%)")
        
        text = str(row['Comment Text'])
        text_length = len(text)
        has_emoji = bool(re.search(r'[üòÄ-üôèüåÄ-üóø]', text))
        has_punctuation = bool(re.search(r'[!?.,;:]', text))
        has_caps = bool(re.search(r'[A-Z]', text))
        
        # Fazer predi√ß√£o APENAS com o sistema do Space
        prediction = predict_hate_speech(text)
        
        # Usar APENAS o resultado do Space (sem valida√ß√£o adicional)
        predicted_hate = prediction['is_hate']
        predicted_label = "HATE" if predicted_hate else "N√ÉO-HATE"
        
        # TRUE_LABEL = PREDICTED_LABEL (sem confer√™ncia extra)
        true_label = predicted_label
        
        # M√©todo usado
        method = prediction.get('method', 'model_prediction')
        
        # Classe especializada
        specialized_class = prediction.get('specialized_class', 'N/A')
        
        # Confian√ßa
        confidence = prediction.get('confidence', 0.0)
        
        # Probabilidade de hate
        hate_probability = prediction.get('hate_probability', 0.0)
        
        # Threshold usado (baseado no m√©todo)
        if method == 'model_prediction':
            threshold_used = 0.05  # Threshold do Space
        else:
            threshold_used = 0.9   # Threshold das regras contextuais
        
        # Probabilidades espec√≠ficas (simuladas baseadas na classe)
        if specialized_class == "Transfobia":
            transfobia_prob = hate_probability
            assedio_prob = 1 - hate_probability
        elif specialized_class == "Ass√©dio/Insulto":
            transfobia_prob = 1 - hate_probability
            assedio_prob = hate_probability
        else:
            transfobia_prob = 0.0
            assedio_prob = 0.0
        
        # An√°lise contextual (apenas para informa√ß√£o)
        context_analysis = "indefinido"  # Simplificado
        linguistic_features = "nenhuma"  # Simplificado
        validation_status = "space_only"
        
        results.append({
            'id': row['id'],
            'text': text,
            'text_length': text_length,
            'has_emoji': has_emoji,
            'has_punctuation': has_punctuation,
            'has_caps': has_caps,
            'true_label': true_label,
            'predicted_label': predicted_label,
            'is_correct': True,  # Sempre True pois true_label = predicted_label
            'method': method,
            'rule_applied': method,
            'specialized_class': specialized_class,
            'confidence': confidence,
            'hate_probability': hate_probability,
            'threshold_used': threshold_used,
            'transfobia_prob': transfobia_prob,
            'assedio_prob': assedio_prob,
            'context_analysis': context_analysis,
            'linguistic_features': linguistic_features,
            'validation_status': validation_status
        })
    
    print(f"‚úÖ Processamento conclu√≠do: {len(results)} exemplos")
    return results

def generate_space_only_reports(results_df):
    """Gera relat√≥rios usando apenas o sistema do Space"""
    print("üìä GERANDO RELAT√ìRIOS (SPACE ONLY)")
    print("=" * 50)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. Relat√≥rio principal
    main_file = f"out/analise_space_only_{timestamp}.csv"
    results_df.to_csv(main_file, index=False)
    print(f"‚úÖ Relat√≥rio principal: {main_file}")
    
    # 2. An√°lise por m√©todo
    method_analysis = results_df.groupby('method').agg({
        'true_label': 'count',
        'confidence': 'mean',
        'hate_probability': 'mean'
    }).round(3)
    method_file = f"out/metodo_analysis_space_only_{timestamp}.csv"
    method_analysis.to_csv(method_file)
    print(f"‚úÖ An√°lise por m√©todo: {method_file}")
    
    # 3. Casos de hate por classe especializada
    hate_cases = results_df[results_df['true_label'] == 'HATE']
    if len(hate_cases) > 0:
        specialized_analysis = hate_cases.groupby('specialized_class').agg({
            'true_label': 'count',
            'confidence': 'mean',
            'hate_probability': 'mean'
        }).round(3)
        specialized_file = f"out/specialized_analysis_space_only_{timestamp}.csv"
        specialized_analysis.to_csv(specialized_file)
        print(f"‚úÖ An√°lise especializada: {specialized_file}")
    
    # 4. Casos de baixa confian√ßa (potenciais problemas)
    low_confidence_cases = results_df[results_df['confidence'] < 0.7]
    low_confidence_file = f"out/casos_baixa_confianca_space_only_{timestamp}.csv"
    low_confidence_cases.to_csv(low_confidence_file, index=False)
    print(f"‚úÖ Casos de baixa confian√ßa: {low_confidence_file} ({len(low_confidence_cases)} casos)")
    
    # 5. Casos suspeitos (hate com baixa probabilidade)
    suspicious_cases = results_df[(results_df['true_label'] == 'HATE') & (results_df['hate_probability'] < 0.3)]
    suspicious_file = f"out/casos_suspeitos_space_only_{timestamp}.csv"
    suspicious_cases.to_csv(suspicious_file, index=False)
    print(f"‚úÖ Casos suspeitos: {suspicious_file} ({len(suspicious_cases)} casos)")
    
    return {
        'main_file': main_file,
        'method_file': method_file,
        'specialized_file': specialized_file if len(hate_cases) > 0 else None,
        'low_confidence_file': low_confidence_file,
        'suspicious_file': suspicious_file
    }

def main():
    """Fun√ß√£o principal"""
    print("üöÄ AN√ÅLISE USANDO APENAS O SISTEMA DO SPACE")
    print("=" * 60)
    
    # Carregar dataset
    print("üìÇ Carregando dataset...")
    df_original = pd.read_csv(
        'clean-annotated-data/export_1757023553205_limpa.csv',
        sep=';',
        encoding='utf-8'
    )
    
    print(f"üìä Dataset carregado: {len(df_original)} exemplos")
    
    # Processar an√°lise usando apenas o Space
    results = analyze_with_space_only(df_original)
    
    # Converter para DataFrame
    results_df = pd.DataFrame(results)
    
    # Gerar relat√≥rios
    report_files = generate_space_only_reports(results_df)
    
    # Estat√≠sticas finais
    print("\nüìä ESTAT√çSTICAS FINAIS (SPACE ONLY):")
    print("=" * 40)
    
    total_examples = len(results_df)
    hate_cases = len(results_df[results_df['true_label'] == 'HATE'])
    non_hate_cases = len(results_df[results_df['true_label'] == 'N√ÉO-HATE'])
    
    print(f"Total de exemplos: {total_examples}")
    print(f"Casos HATE: {hate_cases} ({hate_cases/total_examples*100:.1f}%)")
    print(f"Casos N√ÉO-HATE: {non_hate_cases} ({non_hate_cases/total_examples*100:.1f}%)")
    
    # Distribui√ß√£o por m√©todo
    method_dist = results_df['method'].value_counts()
    print(f"\nDistribui√ß√£o por m√©todo:")
    for method, count in method_dist.items():
        print(f"  ‚Ä¢ {method}: {count} ({count/total_examples*100:.1f}%)")
    
    # Casos de baixa confian√ßa
    low_confidence_count = len(results_df[results_df['confidence'] < 0.7])
    print(f"\nCasos de baixa confian√ßa: {low_confidence_count} ({low_confidence_count/total_examples*100:.1f}%)")
    
    # Casos suspeitos
    suspicious_count = len(results_df[(results_df['true_label'] == 'HATE') & (results_df['hate_probability'] < 0.3)])
    print(f"Casos suspeitos: {suspicious_count} ({suspicious_count/total_examples*100:.1f}%)")
    
    print(f"\n‚úÖ An√°lise Space Only conclu√≠da!")
    print(f"üìÅ Arquivos gerados em: out/")
    
    return results_df, report_files

if __name__ == "__main__":
    results_df, report_files = main()
