#!/usr/bin/env python3
"""
Compara√ß√£o Detalhada: Space vs Redund√¢ncia
Gera planilha com an√°lise lado a lado de ambos os sistemas
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime
import re

# Adicionar o diret√≥rio atual ao path
sys.path.append('.')

# Importar as fun√ß√µes do sistema
from app_space_version import predict_hate_speech

def analyze_context(text):
    """Analisa o contexto do texto"""
    text_lower = text.lower()
    
    # Contexto positivo
    positive_patterns = [
        r'\b(amo|adoro|gosto|aprecio|respeito|apoio|defendo)\b',
        r'\b(orgulho|pride|diversidade|inclus√£o|igualdade)\b',
        r'\b(‚ù§Ô∏è|üíñ|üíï|üåà|üëè|üëç|üéâ|‚ú®)\b'
    ]
    
    # Contexto negativo
    negative_patterns = [
        r'\b(odeio|detesto|nojento|repugnante|asqueroso)\b',
        r'\b(ü§Æ|ü§¢|üò°|üò†|üëé|üíÄ|üëª)\b'
    ]
    
    # Contexto neutro
    neutral_patterns = [
        r'\b(acho|penso|creio|considero|opini√£o)\b',
        r'\b(ü§î|üòê|üòë|üò∂)\b'
    ]
    
    positive_count = sum(1 for pattern in positive_patterns if re.search(pattern, text_lower))
    negative_count = sum(1 for pattern in negative_patterns if re.search(pattern, text_lower))
    neutral_count = sum(1 for pattern in neutral_patterns if re.search(pattern, text_lower))
    
    if positive_count > negative_count and positive_count > neutral_count:
        return "positivo"
    elif negative_count > positive_count and negative_count > neutral_count:
        return "negativo"
    elif neutral_count > 0:
        return "neutro"
    else:
        return "indefinido"

def analyze_linguistic_features(text):
    """Analisa caracter√≠sticas lingu√≠sticas do texto"""
    features = []
    
    # Padr√µes de agressividade
    if re.search(r'[A-Z]{3,}', text):
        features.append("caps_excessive")
    
    if re.search(r'[!]{2,}|[?]{2,}', text):
        features.append("punctuation_excessive")
    
    if re.search(r'\b(viado|bicha|sapat√£o|paneleiro|gay|l√©sbica|bissexual|queer)\b', text.lower()):
        features.append("lgbtqia_terms")
    
    if re.search(r'\b(trans|travesti|transg√™nero|transgenero)\b', text.lower()):
        features.append("trans_terms")
    
    if re.search(r'\b(doen√ßa|doente|tratamento|cura|psicol√≥gico|mental)\b', text.lower()):
        features.append("medical_context")
    
    if re.search(r'\b(pecado|deus|dem√¥nio|igreja|b√≠blia|crist√£o)\b', text.lower()):
        features.append("religious_context")
    
    if re.search(r'\b(natural|normal|anormal|aberra√ß√£o|erro)\b', text.lower()):
        features.append("normality_context")
    
    return ";".join(features) if features else "nenhuma"

def apply_validation_logic(prediction_result, text):
    """Aplica l√≥gica de valida√ß√£o adicional para true_label"""
    
    # Extrair informa√ß√µes da predi√ß√£o
    predicted_hate = prediction_result['is_hate']
    hate_probability = prediction_result['hate_probability']
    method = prediction_result.get('method', 'model_prediction')
    confidence = prediction_result.get('confidence', 0.0)
    
    # An√°lise contextual
    context = analyze_context(text)
    linguistic_features = analyze_linguistic_features(text)
    
    # L√≥gica de confer√™ncia extra
    true_hate = predicted_hate  # Base inicial
    original_hate = predicted_hate  # Para debug
    
    # 1. Confer√™ncia por contexto (MAIS AGRESSIVA)
    if context == "positivo" and predicted_hate:
        # Se contexto √© positivo mas foi classificado como hate, SEMPRE revisar
        if "lgbtqia_terms" in linguistic_features and "orgulho" in text.lower():
            # Casos de orgulho LGBTQIA+ = SEMPRE N√ÉO-HATE
            true_hate = False
        elif hate_probability < 0.9:  # Baixa confian√ßa
            true_hate = False
        elif "lgbtqia_terms" in linguistic_features:
            # Manter hate se tem termos LGBTQIA+ mas sem contexto de orgulho
            true_hate = True
    
    # 2. Confer√™ncia por caracter√≠sticas lingu√≠sticas
    if "medical_context" in linguistic_features and predicted_hate:
        # Contexto m√©dico + hate = provavelmente transfobia
        true_hate = True
    
    if "religious_context" in linguistic_features and predicted_hate:
        # Contexto religioso + hate = provavelmente transfobia
        true_hate = True
    
    if "normality_context" in linguistic_features and predicted_hate:
        # Contexto de normalidade + hate = provavelmente transfobia
        true_hate = True
    
    # 3. Confer√™ncia por padr√µes de falsos positivos √≥bvios
    if predicted_hate and context == "positivo":
        # Padr√µes de orgulho e afirma√ß√£o = SEMPRE N√ÉO-HATE
        pride_patterns = [
            "com muito orgulho", "com orgulho", "sou orgulhoso", "sou orgulhosa",
            "me orgulho", "orgulho de ser", "orgulho de mim", "orgulho da minha"
        ]
        if any(pattern in text.lower() for pattern in pride_patterns):
            true_hate = False
    
    # 4. Confer√™ncia por padr√µes de respeito e aceita√ß√£o
    if predicted_hate and context == "positivo":
        # Padr√µes de respeito = SEMPRE N√ÉO-HATE
        respect_patterns = [
            "respeitar", "respeito", "aceitar", "aceita√ß√£o", "toler√¢ncia",
            "diversidade", "inclus√£o", "igualdade", "direitos", "direito de ser"
        ]
        if any(pattern in text.lower() for pattern in respect_patterns):
            true_hate = False
    
    # 5. Confer√™ncia por m√©todo
    if method in ['mocking_emoji_rule', 'curse_words_rule', 'direct_insults_rule']:
        # Regras espec√≠ficas t√™m alta confian√ßa
        true_hate = predicted_hate
    
    # 6. Confer√™ncia por threshold adaptativo
    if method == 'model_prediction':
        # Para predi√ß√µes do modelo, aplicar threshold mais rigoroso
        if hate_probability >= 0.7:  # Threshold mais alto para confirma√ß√£o
            true_hate = True
        elif hate_probability <= 0.3:  # Threshold mais baixo para rejei√ß√£o
            true_hate = False
        else:
            # Zona de incerteza - manter predi√ß√£o original
            true_hate = predicted_hate
    
    return true_hate, context, linguistic_features

def compare_space_vs_redundancy(df_final):
    """Compara Space vs Redund√¢ncia para cada caso"""
    print("üîç COMPARANDO SPACE VS REDUND√ÇNCIA")
    print("=" * 50)
    
    results = []
    total_examples = len(df_final)
    
    for idx, row in df_final.iterrows():
        if idx % 100 == 0:
            print(f"üìà Progresso: {idx}/{total_examples} ({idx/total_examples*100:.1f}%)")
        
        text = str(row['Comment Text'])
        text_length = len(text)
        has_emoji = bool(re.search(r'[üòÄ-üôèüåÄ-üóø]', text))
        has_punctuation = bool(re.search(r'[!?.,;:]', text))
        has_caps = bool(re.search(r'[A-Z]', text))
        
        # === AN√ÅLISE DO SPACE ===
        space_prediction = predict_hate_speech(text)
        
        space_hate = space_prediction['is_hate']
        space_label = "HATE" if space_hate else "N√ÉO-HATE"
        space_method = space_prediction.get('method', 'model_prediction')
        space_specialized = space_prediction.get('specialized_class', 'N/A')
        space_confidence = space_prediction.get('confidence', 0.0)
        space_hate_prob = space_prediction.get('hate_probability', 0.0)
        space_threshold = 0.05 if space_method == 'model_prediction' else 0.9
        
        # === AN√ÅLISE DA REDUND√ÇNCIA ===
        redundancy_hate, context_analysis, linguistic_features = apply_validation_logic(space_prediction, text)
        redundancy_label = "HATE" if redundancy_hate else "N√ÉO-HATE"
        redundancy_threshold = 0.7 if space_method == 'model_prediction' else 0.9
        
        # === COMPARA√á√ÉO ===
        labels_differ = space_label != redundancy_label
        is_correct = space_hate == redundancy_hate
        
        # === DETEC√á√ÉO DE PADR√ïES ===
        pride_patterns = [
            "com muito orgulho", "com orgulho", "sou orgulhoso", "sou orgulhosa",
            "me orgulho", "orgulho de ser", "orgulho de mim", "orgulho da minha"
        ]
        has_pride_pattern = any(pattern in text.lower() for pattern in pride_patterns)
        
        respect_patterns = [
            "respeitar", "respeito", "aceitar", "aceita√ß√£o", "toler√¢ncia",
            "diversidade", "inclus√£o", "igualdade", "direitos", "direito de ser"
        ]
        has_respect_pattern = any(pattern in text.lower() for pattern in respect_patterns)
        
        # === CLASSIFICA√á√ÉO DO TIPO DE CASO ===
        case_type = "normal"
        if labels_differ:
            if space_hate and not redundancy_hate:
                case_type = "falso_positivo_corrigido"
            elif not space_hate and redundancy_hate:
                case_type = "falso_negativo_corrigido"
        
        if space_hate and space_hate_prob < 0.3:
            case_type = "suspeito_space"
        
        if has_pride_pattern and space_hate:
            case_type = "orgulho_classificado_hate"
        
        if has_respect_pattern and space_hate:
            case_type = "respeito_classificado_hate"
        
        results.append({
            # === INFORMA√á√ïES B√ÅSICAS ===
            'id': row['id'],
            'text': text,
            'text_length': text_length,
            'has_emoji': has_emoji,
            'has_punctuation': has_punctuation,
            'has_caps': has_caps,
            
            # === AN√ÅLISE DO SPACE ===
            'space_label': space_label,
            'space_hate': space_hate,
            'space_method': space_method,
            'space_specialized_class': space_specialized,
            'space_confidence': space_confidence,
            'space_hate_probability': space_hate_prob,
            'space_threshold_used': space_threshold,
            
            # === AN√ÅLISE DA REDUND√ÇNCIA ===
            'redundancy_label': redundancy_label,
            'redundancy_hate': redundancy_hate,
            'redundancy_threshold_used': redundancy_threshold,
            'redundancy_context_analysis': context_analysis,
            'redundancy_linguistic_features': linguistic_features,
            
            # === COMPARA√á√ÉO ===
            'labels_differ': labels_differ,
            'is_correct': is_correct,
            'case_type': case_type,
            
            # === DETEC√á√ÉO DE PADR√ïES ===
            'has_pride_pattern': has_pride_pattern,
            'has_respect_pattern': has_respect_pattern,
            'context_analysis': context_analysis,
            'linguistic_features': linguistic_features,
            
            # === AN√ÅLISE DETALHADA ===
            'space_vs_redundancy': f"{space_label} ‚Üí {redundancy_label}",
            'threshold_difference': redundancy_threshold - space_threshold,
            'confidence_level': "alta" if space_confidence >= 0.9 else "m√©dia" if space_confidence >= 0.7 else "baixa",
            'method_type': "regra_contextual" if space_method != 'model_prediction' else "modelo_binario"
        })
    
    print(f"‚úÖ Compara√ß√£o conclu√≠da: {len(results)} exemplos")
    return results

def generate_comparison_reports(results_df):
    """Gera relat√≥rios de compara√ß√£o"""
    print("üìä GERANDO RELAT√ìRIOS DE COMPARA√á√ÉO")
    print("=" * 50)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. Relat√≥rio principal de compara√ß√£o
    main_file = f"out/comparacao_space_vs_redundancy_{timestamp}.csv"
    results_df.to_csv(main_file, index=False)
    print(f"‚úÖ Relat√≥rio principal: {main_file}")
    
    # 2. Casos onde h√° diferen√ßa
    different_cases = results_df[results_df['labels_differ'] == True]
    different_file = f"out/casos_diferentes_space_vs_redundancy_{timestamp}.csv"
    different_cases.to_csv(different_file, index=False)
    print(f"‚úÖ Casos diferentes: {different_file} ({len(different_cases)} casos)")
    
    # 3. An√°lise por tipo de caso
    case_type_analysis = results_df.groupby('case_type').agg({
        'id': 'count',
        'space_confidence': 'mean',
        'space_hate_probability': 'mean',
        'labels_differ': 'sum'
    }).round(3)
    case_type_file = f"out/analise_por_tipo_caso_{timestamp}.csv"
    case_type_analysis.to_csv(case_type_file)
    print(f"‚úÖ An√°lise por tipo: {case_type_file}")
    
    # 4. An√°lise por m√©todo do Space
    method_analysis = results_df.groupby('space_method').agg({
        'id': 'count',
        'labels_differ': 'sum',
        'space_confidence': 'mean',
        'space_hate_probability': 'mean'
    }).round(3)
    method_file = f"out/analise_por_metodo_space_{timestamp}.csv"
    method_analysis.to_csv(method_file)
    print(f"‚úÖ An√°lise por m√©todo: {method_file}")
    
    # 5. Casos suspeitos do Space
    suspicious_cases = results_df[results_df['case_type'] == 'suspeito_space']
    suspicious_file = f"out/casos_suspeitos_space_{timestamp}.csv"
    suspicious_cases.to_csv(suspicious_file, index=False)
    print(f"‚úÖ Casos suspeitos: {suspicious_file} ({len(suspicious_cases)} casos)")
    
    # 6. Casos de orgulho classificados como hate
    pride_hate_cases = results_df[results_df['case_type'] == 'orgulho_classificado_hate']
    pride_hate_file = f"out/orgulho_classificado_hate_{timestamp}.csv"
    pride_hate_cases.to_csv(pride_hate_file, index=False)
    print(f"‚úÖ Orgulho como hate: {pride_hate_file} ({len(pride_hate_cases)} casos)")
    
    # 7. Casos de respeito classificados como hate
    respect_hate_cases = results_df[results_df['case_type'] == 'respeito_classificado_hate']
    respect_hate_file = f"out/respeito_classificado_hate_{timestamp}.csv"
    respect_hate_cases.to_csv(respect_hate_file, index=False)
    print(f"‚úÖ Respeito como hate: {respect_hate_file} ({len(respect_hate_cases)} casos)")
    
    return {
        'main_file': main_file,
        'different_file': different_file,
        'case_type_file': case_type_file,
        'method_file': method_file,
        'suspicious_file': suspicious_file,
        'pride_hate_file': pride_hate_file,
        'respect_hate_file': respect_hate_file
    }

def main():
    """Fun√ß√£o principal"""
    print("üöÄ COMPARA√á√ÉO DETALHADA: SPACE VS REDUND√ÇNCIA")
    print("=" * 60)
    
    # Carregar dataset
    print("üìÇ Carregando dataset...")
    df_original = pd.read_csv(
        'clean-annotated-data/export_1757023553205_limpa.csv',
        sep=';',
        encoding='utf-8'
    )
    
    print(f"üìä Dataset carregado: {len(df_original)} exemplos")
    
    # Processar compara√ß√£o
    results = compare_space_vs_redundancy(df_original)
    
    # Converter para DataFrame
    results_df = pd.DataFrame(results)
    
    # Gerar relat√≥rios
    report_files = generate_comparison_reports(results_df)
    
    # Estat√≠sticas finais
    print("\nüìä ESTAT√çSTICAS FINAIS DA COMPARA√á√ÉO:")
    print("=" * 50)
    
    total_examples = len(results_df)
    different_cases = len(results_df[results_df['labels_differ'] == True])
    space_hate = len(results_df[results_df['space_label'] == 'HATE'])
    redundancy_hate = len(results_df[results_df['redundancy_label'] == 'HATE'])
    
    print(f"Total de exemplos: {total_examples}")
    print(f"Casos onde h√° diferen√ßa: {different_cases} ({different_cases/total_examples*100:.1f}%)")
    print(f"Space - Casos HATE: {space_hate} ({space_hate/total_examples*100:.1f}%)")
    print(f"Redund√¢ncia - Casos HATE: {redundancy_hate} ({redundancy_hate/total_examples*100:.1f}%)")
    
    # An√°lise por tipo de caso
    case_type_dist = results_df['case_type'].value_counts()
    print(f"\nDistribui√ß√£o por tipo de caso:")
    for case_type, count in case_type_dist.items():
        print(f"  ‚Ä¢ {case_type}: {count} ({count/total_examples*100:.1f}%)")
    
    # An√°lise por m√©todo
    method_dist = results_df['space_method'].value_counts()
    print(f"\nDistribui√ß√£o por m√©todo do Space:")
    for method, count in method_dist.items():
        print(f"  ‚Ä¢ {method}: {count} ({count/total_examples*100:.1f}%)")
    
    print(f"\n‚úÖ Compara√ß√£o conclu√≠da!")
    print(f"üìÅ Arquivos gerados em: out/")
    
    return results_df, report_files

if __name__ == "__main__":
    results_df, report_files = main()
