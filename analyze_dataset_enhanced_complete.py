#!/usr/bin/env python3
"""
An√°lise Completa Aprimorada da Base Limpa
Inclui valida√ß√£o adicional, colunas importantes e an√°lise contextual
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime
import re
import json

# Adicionar o diret√≥rio atual ao path
sys.path.append('.')

# Importar as fun√ß√µes do sistema
from app_space_version import predict_hate_speech

def analyze_context(text):
    """Analisa o contexto do texto"""
    text_lower = text.lower()
    
    # Contexto positivo
    positive_patterns = [
        r'\b(amo|adoro|gosto|aprecio|respeito|apoio|defendo)\b',
        r'\b(orgulho|pride|diversidade|inclus√£o|igualdade)\b',
        r'\b(‚ù§Ô∏è|üíñ|üíï|üåà|üëè|üëç|üéâ|‚ú®)\b'
    ]
    
    # Contexto negativo
    negative_patterns = [
        r'\b(odeio|detesto|nojento|repugnante|asqueroso)\b',
        r'\b(ü§Æ|ü§¢|üò°|üò†|üëé|üíÄ|üëª)\b'
    ]
    
    # Contexto neutro
    neutral_patterns = [
        r'\b(acho|penso|creio|considero|opini√£o)\b',
        r'\b(ü§î|üòê|üòë|üò∂)\b'
    ]
    
    positive_count = sum(1 for pattern in positive_patterns if re.search(pattern, text_lower))
    negative_count = sum(1 for pattern in negative_patterns if re.search(pattern, text_lower))
    neutral_count = sum(1 for pattern in neutral_patterns if re.search(pattern, text_lower))
    
    if positive_count > negative_count and positive_count > neutral_count:
        return "positivo"
    elif negative_count > positive_count and negative_count > neutral_count:
        return "negativo"
    elif neutral_count > 0:
        return "neutro"
    else:
        return "indefinido"

def analyze_linguistic_features(text):
    """Analisa caracter√≠sticas lingu√≠sticas do texto"""
    features = []
    
    # Padr√µes de agressividade
    if re.search(r'[A-Z]{3,}', text):
        features.append("caps_excessive")
    
    if re.search(r'[!]{2,}|[?]{2,}', text):
        features.append("punctuation_excessive")
    
    if re.search(r'\b(viado|bicha|sapat√£o|paneleiro|gay|l√©sbica|bissexual|queer)\b', text.lower()):
        features.append("lgbtqia_terms")
    
    if re.search(r'\b(trans|travesti|transg√™nero|transgenero)\b', text.lower()):
        features.append("trans_terms")
    
    if re.search(r'\b(doen√ßa|doente|tratamento|cura|psicol√≥gico|mental)\b', text.lower()):
        features.append("medical_context")
    
    if re.search(r'\b(pecado|deus|dem√¥nio|igreja|b√≠blia|crist√£o)\b', text.lower()):
        features.append("religious_context")
    
    if re.search(r'\b(natural|normal|anormal|aberra√ß√£o|erro)\b', text.lower()):
        features.append("normality_context")
    
    return ";".join(features) if features else "nenhuma"

def apply_validation_logic(prediction_result, text):
    """Aplica l√≥gica de valida√ß√£o adicional para true_label"""
    
    # Extrair informa√ß√µes da predi√ß√£o
    predicted_hate = prediction_result['is_hate']
    hate_probability = prediction_result['hate_probability']
    method = prediction_result.get('method', 'model_prediction')
    confidence = prediction_result.get('confidence', 0.0)
    
    # An√°lise contextual
    context = analyze_context(text)
    linguistic_features = analyze_linguistic_features(text)
    
    # L√≥gica de confer√™ncia extra
    true_hate = predicted_hate  # Base inicial
    original_hate = predicted_hate  # Para debug
    
    # 1. Confer√™ncia por contexto (MAIS AGRESSIVA)
    if context == "positivo" and predicted_hate:
        # Se contexto √© positivo mas foi classificado como hate, SEMPRE revisar
        if "lgbtqia_terms" in linguistic_features and "orgulho" in text.lower():
            # Casos de orgulho LGBTQIA+ = SEMPRE N√ÉO-HATE
            true_hate = False
        elif hate_probability < 0.9:  # Baixa confian√ßa
            true_hate = False
        elif "lgbtqia_terms" in linguistic_features:
            # Manter hate se tem termos LGBTQIA+ mas sem contexto de orgulho
            true_hate = True
    
    # 2. Confer√™ncia por caracter√≠sticas lingu√≠sticas
    if "medical_context" in linguistic_features and predicted_hate:
        # Contexto m√©dico + hate = provavelmente transfobia
        true_hate = True
    
    if "religious_context" in linguistic_features and predicted_hate:
        # Contexto religioso + hate = provavelmente transfobia
        true_hate = True
    
    if "normality_context" in linguistic_features and predicted_hate:
        # Contexto de normalidade + hate = provavelmente transfobia
        true_hate = True
    
    # 3. Confer√™ncia por padr√µes de falsos positivos √≥bvios
    if predicted_hate and context == "positivo":
        # Padr√µes de orgulho e afirma√ß√£o = SEMPRE N√ÉO-HATE
        pride_patterns = [
            "com muito orgulho", "com orgulho", "sou orgulhoso", "sou orgulhosa",
            "me orgulho", "orgulho de ser", "orgulho de mim", "orgulho da minha"
        ]
        if any(pattern in text.lower() for pattern in pride_patterns):
            true_hate = False
    
    # 4. Confer√™ncia por padr√µes de respeito e aceita√ß√£o
    if predicted_hate and context == "positivo":
        # Padr√µes de respeito = SEMPRE N√ÉO-HATE
        respect_patterns = [
            "respeitar", "respeito", "aceitar", "aceita√ß√£o", "toler√¢ncia",
            "diversidade", "inclus√£o", "igualdade", "direitos", "direito de ser"
        ]
        if any(pattern in text.lower() for pattern in respect_patterns):
            true_hate = False
    
    # 3. Confer√™ncia por m√©todo
    if method in ['mocking_emoji_rule', 'curse_words_rule', 'direct_insults_rule']:
        # Regras espec√≠ficas t√™m alta confian√ßa
        true_hate = predicted_hate
    
    # 4. Confer√™ncia por threshold adaptativo
    if method == 'model_prediction':
        # Para predi√ß√µes do modelo, aplicar threshold mais rigoroso
        if hate_probability >= 0.7:  # Threshold mais alto para confirma√ß√£o
            true_hate = True
        elif hate_probability <= 0.3:  # Threshold mais baixo para rejei√ß√£o
            true_hate = False
        else:
            # Zona de incerteza - manter predi√ß√£o original
            true_hate = predicted_hate
    
    return true_hate

def analyze_with_enhanced_system(df_final):
    """An√°lise com sistema aprimorado incluindo valida√ß√£o adicional"""
    print("üîç AN√ÅLISE COM SISTEMA APRIMORADO")
    print("=" * 50)
    
    results = []
    total_examples = len(df_final)
    
    for idx, row in df_final.iterrows():
        if idx % 100 == 0:
            print(f"üìà Progresso: {idx}/{total_examples} ({idx/total_examples*100:.1f}%)")
        
        text = str(row['Comment Text'])
        text_length = len(text)
        has_emoji = bool(re.search(r'[üòÄ-üôèüåÄ-üóø]', text))
        has_punctuation = bool(re.search(r'[!?.,;:]', text))
        has_caps = bool(re.search(r'[A-Z]', text))
        
        # Fazer predi√ß√£o
        prediction = predict_hate_speech(text)
        
        # Aplicar valida√ß√£o adicional
        true_hate = apply_validation_logic(prediction, text)
        
        # Determinar labels
        predicted_hate = prediction['is_hate']
        predicted_label = "HATE" if predicted_hate else "N√ÉO-HATE"
        true_label = "HATE" if true_hate else "N√ÉO-HATE"
        
        # Verificar se est√° correto
        is_correct = predicted_hate == true_hate
        
        # An√°lise contextual
        context_analysis = analyze_context(text)
        linguistic_features = analyze_linguistic_features(text)
        
        # M√©todo usado
        method = prediction.get('method', 'model_prediction')
        
        # Classe especializada
        specialized_class = prediction.get('specialized_class', 'N/A')
        
        # Confian√ßa
        confidence = prediction.get('confidence', 0.0)
        
        # Probabilidade de hate
        hate_probability = prediction.get('hate_probability', 0.0)
        
        # Threshold usado (baseado no m√©todo)
        threshold_used = 0.7 if method == 'model_prediction' else 0.9
        
        # Probabilidades espec√≠ficas (simuladas baseadas na classe)
        if specialized_class == "Transfobia":
            transfobia_prob = hate_probability
            assedio_prob = 1 - hate_probability
        elif specialized_class == "Ass√©dio/Insulto":
            transfobia_prob = 1 - hate_probability
            assedio_prob = hate_probability
        else:
            transfobia_prob = 0.0
            assedio_prob = 0.0
        
        # Status da valida√ß√£o
        validation_status = "autom√°tica" if method != 'model_prediction' else "manual"
        
        results.append({
            'id': row['id'],
            'text': text,
            'text_length': text_length,
            'has_emoji': has_emoji,
            'has_punctuation': has_punctuation,
            'has_caps': has_caps,
            'true_label': true_label,
            'predicted_label': predicted_label,
            'is_correct': is_correct,
            'method': method,
            'rule_applied': method,
            'specialized_class': specialized_class,
            'confidence': confidence,
            'hate_probability': hate_probability,
            'threshold_used': threshold_used,
            'transfobia_prob': transfobia_prob,
            'assedio_prob': assedio_prob,
            'context_analysis': context_analysis,
            'linguistic_features': linguistic_features,
            'validation_status': validation_status
        })
    
    print(f"‚úÖ Processamento conclu√≠do: {len(results)} exemplos")
    return results

def generate_enhanced_reports(results_df):
    """Gera relat√≥rios aprimorados com todas as colunas"""
    print("üìä GERANDO RELAT√ìRIOS APRIMORADOS")
    print("=" * 50)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. Relat√≥rio principal aprimorado
    main_file = f"out/analise_enhanced_completa_{timestamp}.csv"
    results_df.to_csv(main_file, index=False)
    print(f"‚úÖ Relat√≥rio principal: {main_file}")
    
    # 2. An√°lise de valida√ß√£o
    validation_analysis = results_df.groupby(['true_label', 'predicted_label']).size().unstack(fill_value=0)
    validation_file = f"out/validacao_analysis_{timestamp}.csv"
    validation_analysis.to_csv(validation_file)
    print(f"‚úÖ An√°lise de valida√ß√£o: {validation_file}")
    
    # 3. An√°lise por m√©todo
    method_analysis = results_df.groupby('method').agg({
        'true_label': 'count',
        'is_correct': 'sum',
        'confidence': 'mean',
        'hate_probability': 'mean'
    }).round(3)
    method_file = f"out/metodo_analysis_{timestamp}.csv"
    method_analysis.to_csv(method_file)
    print(f"‚úÖ An√°lise por m√©todo: {method_file}")
    
    # 4. An√°lise contextual
    context_analysis = results_df.groupby('context_analysis').agg({
        'true_label': 'count',
        'is_correct': 'sum',
        'confidence': 'mean'
    }).round(3)
    context_file = f"out/contexto_analysis_{timestamp}.csv"
    context_analysis.to_csv(context_file)
    print(f"‚úÖ An√°lise contextual: {context_file}")
    
    # 5. An√°lise de caracter√≠sticas lingu√≠sticas
    linguistic_analysis = results_df.groupby('linguistic_features').agg({
        'true_label': 'count',
        'is_correct': 'sum',
        'confidence': 'mean'
    }).round(3)
    linguistic_file = f"out/linguistic_analysis_{timestamp}.csv"
    linguistic_analysis.to_csv(linguistic_file)
    print(f"‚úÖ An√°lise lingu√≠stica: {linguistic_file}")
    
    # 6. Casos de discord√¢ncia (true_label != predicted_label)
    discordance_cases = results_df[results_df['true_label'] != results_df['predicted_label']]
    discordance_file = f"out/casos_discordancia_{timestamp}.csv"
    discordance_cases.to_csv(discordance_file, index=False)
    print(f"‚úÖ Casos de discord√¢ncia: {discordance_file} ({len(discordance_cases)} casos)")
    
    # 7. Casos de alta confian√ßa
    high_confidence_cases = results_df[results_df['confidence'] >= 0.9]
    high_confidence_file = f"out/casos_alta_confianca_{timestamp}.csv"
    high_confidence_cases.to_csv(high_confidence_file, index=False)
    print(f"‚úÖ Casos de alta confian√ßa: {high_confidence_file} ({len(high_confidence_cases)} casos)")
    
    # 8. Casos de baixa confian√ßa
    low_confidence_cases = results_df[results_df['confidence'] < 0.7]
    low_confidence_file = f"out/casos_baixa_confianca_{timestamp}.csv"
    low_confidence_cases.to_csv(low_confidence_file, index=False)
    print(f"‚úÖ Casos de baixa confian√ßa: {low_confidence_file} ({len(low_confidence_cases)} casos)")
    
    return {
        'main_file': main_file,
        'validation_file': validation_file,
        'method_file': method_file,
        'context_file': context_file,
        'linguistic_file': linguistic_file,
        'discordance_file': discordance_file,
        'high_confidence_file': high_confidence_file,
        'low_confidence_file': low_confidence_file
    }

def main():
    """Fun√ß√£o principal"""
    print("üöÄ AN√ÅLISE COMPLETA APRIMORADA DA BASE LIMPA")
    print("=" * 60)
    
    # Carregar dataset
    print("üìÇ Carregando dataset...")
    df_original = pd.read_csv(
        'clean-annotated-data/export_1757023553205_limpa.csv',
        sep=';',
        encoding='utf-8'
    )
    
    print(f"üìä Dataset carregado: {len(df_original)} exemplos")
    
    # Processar an√°lise aprimorada
    results = analyze_with_enhanced_system(df_original)
    
    # Converter para DataFrame
    results_df = pd.DataFrame(results)
    
    # Gerar relat√≥rios aprimorados
    report_files = generate_enhanced_reports(results_df)
    
    # Estat√≠sticas finais
    print("\nüìä ESTAT√çSTICAS FINAIS:")
    print("=" * 30)
    
    total_examples = len(results_df)
    correct_predictions = results_df['is_correct'].sum()
    accuracy = correct_predictions / total_examples
    
    print(f"Total de exemplos: {total_examples}")
    print(f"Predi√ß√µes corretas: {correct_predictions}")
    print(f"Accuracy: {accuracy:.1%}")
    
    # Distribui√ß√£o por true_label
    true_label_dist = results_df['true_label'].value_counts()
    print(f"\nDistribui√ß√£o por true_label:")
    for label, count in true_label_dist.items():
        print(f"  ‚Ä¢ {label}: {count} ({count/total_examples*100:.1f}%)")
    
    # Distribui√ß√£o por m√©todo
    method_dist = results_df['method'].value_counts()
    print(f"\nDistribui√ß√£o por m√©todo:")
    for method, count in method_dist.items():
        print(f"  ‚Ä¢ {method}: {count} ({count/total_examples*100:.1f}%)")
    
    # Casos de discord√¢ncia
    discordance_count = len(results_df[results_df['true_label'] != results_df['predicted_label']])
    print(f"\nCasos de discord√¢ncia: {discordance_count} ({discordance_count/total_examples*100:.1f}%)")
    
    print(f"\n‚úÖ An√°lise aprimorada conclu√≠da!")
    print(f"üìÅ Arquivos gerados em: out/")
    
    return results_df, report_files

if __name__ == "__main__":
    results_df, report_files = main()
