---
license: mit
language:
- pt
tags:
- hate-speech-detection
- lgbtqia
- portuguese
- bertimbau
- ensemble
pipeline_tag: text-classification
---

# Radar Social LGBTQIA+

Sistema de detecÃ§Ã£o de discurso de Ã³dio contra pessoas LGBTQIA+ em portuguÃªs brasileiro.

## ğŸ¯ Objetivo

Detectar e classificar discurso de Ã³dio contra pessoas LGBTQIA+ em textos em portuguÃªs brasileiro, com foco especial em transfobia e assÃ©dio.

## ğŸ—ï¸ Arquitetura

Sistema ensemble com dois modelos:

1. **Modelo BinÃ¡rio**: Filtra hate/nÃ£o-hate (80.14% acurÃ¡cia)
2. **Modelo Especializado**: Classifica tipos especÃ­ficos (99.17% acurÃ¡cia)
   - Transfobia
   - AssÃ©dio/Insulto

## ğŸš€ Uso RÃ¡pido

### InstalaÃ§Ã£o
```bash
pip install transformers torch pandas scikit-learn
```

### PrediÃ§Ã£o Simples
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# Carregar modelo binÃ¡rio
tokenizer = AutoTokenizer.from_pretrained("Veronyka/radar-social-lgbtqia", subfolder="model-binary-expanded")
model = AutoModelForSequenceClassification.from_pretrained("Veronyka/radar-social-lgbtqia", subfolder="model-binary-expanded")

# PrediÃ§Ã£o
text = "Texto para analisar"
inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
with torch.no_grad():
    outputs = model(**inputs)
    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
    print(f"Probabilidade de hate: {predictions[0][1]:.3f}")
```

## ğŸ“Š Performance

- **AcurÃ¡cia BinÃ¡ria**: 80.14%
- **AcurÃ¡cia Especializada**: 99.17%
- **ConfianÃ§a MÃ©dia**: 93.9%
- **Taxa de Processamento**: 28.9 textos/segundo

## ğŸ”’ Privacidade

- Dados pessoais removidos durante treinamento
- Apenas conteÃºdo linguÃ­stico preservado
- Conformidade com LGPD/GDPR

## ğŸ“Š Datasets Utilizados no Treinamento

### Modelos Base
- **BERTimbau**: https://hf.co/neuralmind/bert-base-portuguese-cased
- **Helsinki-NLP Translation**: https://hf.co/Helsinki-NLP/opus-mt-tc-big-en-pt

### Datasets Externos
- **ToLD-BR**: https://github.com/joaoaleite/ToLD-Br/
- **Anti-LGBT Cyberbullying**: https://www.kaggle.com/datasets/kw5454331/anti-lgbt-cyberbullying-texts/data

### Dataset de Treinamento do BERTimbau
- **HateBR**: https://hf.co/datasets/ruanchaves/hatebr (excluÃ­do por data leakage)

### Fontes dos Dados
- **Dados manuais**: AnotaÃ§Ãµes da equipe CÃ³digo NÃ£o BinÃ¡rio sobre o podcast Entre Amigues
- **ToLD-BR**: Dataset brasileiro de toxicidade (GitHub)
- **Anti-LGBT**: Dataset inglÃªs traduzido para PT-BR (Kaggle)

## ğŸ”— Links Relacionados

- [Base de Dados de Ã“dio LGBTQIA+](https://github.com/travahacker/base-dados-odio-lgbtqia)
- [Hugging Face Dataset](https://hf.co/datasets/Veronyka/base-dados-odio-lgbtqia)

## ğŸ“„ LicenÃ§a

MIT License - Veja LICENSE para detalhes.

## âš ï¸ Aviso Importante

Este modelo foi treinado com dados de discurso de Ã³dio real. Use com responsabilidade e sempre considere o impacto Ã©tico de suas aplicaÃ§Ãµes.

## ğŸ“ Contato

Para questÃµes sobre o modelo ou colaboraÃ§Ãµes, entre em contato atravÃ©s das issues do repositÃ³rio.
