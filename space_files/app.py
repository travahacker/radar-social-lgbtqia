import gradio as gr
import pandas as pd
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import pickle
import json
import re
import hashlib
import os
import warnings

warnings.filterwarnings("ignore")

# --- Configura√ß√µes ---
DEVICE = "cpu"  # Simplificado para evitar problemas de GPU
MODEL_PATH = "Veronyka/radar-social-lgbtqia"

# --- Normaliza√ß√£o de Texto ---
def normalize_text(text):
    text = str(text).lower()
    text = re.sub(r"http\S+|www\S+|https\S+", "[URL]", text, flags=re.MULTILINE)
    text = re.sub(r"@\w+", "[MENTION]", text)
    text = re.sub(r"#\w+", "[HASHTAG]", text)
    text = re.sub(r"[^\w\s\[\]]", "", text) # Remove pontua√ß√£o, mas mant√©m []
    text = re.sub(r"\s+", " ", text).strip()
    return text

# --- REGRAS ESPEC√çFICAS PARA CASOS PROBLEM√ÅTICOS ---
def detect_neutral_language_opposition(text):
    """Detecta oposi√ß√£o √† linguagem neutra"""
    text_lower = text.lower()
    
    patterns = [
        r'\btodes\b.*\b(√©|s√£o|foi|era)\b.*\b(meu|meus|minha|minhas)\b.*\b(ovo|ovos|egg|eggs)\b',
        r'\b(quem|pessoa).*\bfala\b.*\btodes\b.*\b(retardado|retardades|burro|burra)\b',
        r'\btodes\b.*\b(fim da picada|babaquice|idiota|burro)\b',
        r'\b(modinha|frescura)\b.*\b(todes|linguagem neutra)\b'
    ]
    
    for pattern in patterns:
        if re.search(pattern, text_lower):
            return True
    return False

def detect_clown_emoji_context(text):
    """Detecta contexto de emojis de palha√ßo"""
    patterns = [
        r'üòÇ+.*\b(todes|linguagem neutra|neutral)\b',
        r'\b(todes|oves|lules)\b.*üòÇ+',
        r'üòÇ+.*\b(ovo|ovos|egg|eggs)\b',
        r'\b(ovo|ovos|egg|eggs)\b.*üòÇ+'
    ]
    
    for pattern in patterns:
        if re.search(pattern, text):
            return True
    return False

def detect_curse_words_neutral_context(text):
    """Detecta palavr√µes em contexto neutro"""
    text_lower = text.lower()
    
    patterns = [
        r'\b(porra|merda|bosta)\b.*\b(todes|linguagem neutra)\b',
        r'\b(meu amigo|mano|gente)\b.*\b(porra|merda|bosta)\b',
        r'\b(porra|merda|bosta)\b.*\b(que|isso|essa)\b.*\b(coisa|situa√ß√£o)\b',
        r'\b(porra|merda|bosta)\b.*\btodes\b.*\.\.\.',  # "Porra de todes..."
        r'\b(porra|merda|bosta)\b.*\btodes\b$'  # "Porra de todes" (final da frase)
    ]
    
    for pattern in patterns:
        if re.search(pattern, text_lower):
            return True
    return False

def detect_tiredness_expressions(text):
    """Detecta express√µes de cansa√ßo/des√¢nimo"""
    text_lower = text.lower()
    
    patterns = [
        r'\b(que|que) (pregui√ßa|cansa√ßo|des√¢nimo|fadiga)\b',
        r'\b(pregui√ßa|cansa√ßo|des√¢nimo|fadiga)\b.*\b(desse|dessa|disso)\b',
        r'\b(estou|t√¥|estou) (cansado|cansada|exausto|exausta)\b'
    ]
    
    for pattern in patterns:
        if re.search(pattern, text_lower):
            return True
    return False

def detect_religious_neutral_expressions(text):
    """Detecta express√µes religiosas neutras"""
    text_lower = text.lower()
    
    patterns = [
        r'\b(meu|ai) deus\b',
        r'\bnossa senhora\b',
        r'\bdeus do c√©u\b',
        r'\b(ai|meu) deus\b.*\b(que|isso|essa)\b'
    ]
    
    for pattern in patterns:
        if re.search(pattern, text_lower):
            return True
    return False

def detect_vomit_emoji_context(text):
    """Detecta contexto de emojis de v√¥mito"""
    patterns = [
        r'ü§¢ü§Æ',
        r'ü§Æü§¢',
        r'ü§¢.*ü§Æ',
        r'ü§Æ.*ü§¢'
    ]
    
    for pattern in patterns:
        if re.search(pattern, text):
            return True
    return False

def detect_laughter_context_neutral(text):
    """Detecta emojis de risada em contexto neutro"""
    patterns = [
        r'üòÇ+.*\b(insignificante|sacanagem|brincadeira|piada)\b',
        r'\b(insignificante|sacanagem|brincadeira|piada)\b.*üòÇ+',
        r'üòÇ+$',  # Apenas emojis de risada no final
        r'^üòÇ+$'  # Apenas emojis de risada
    ]
    
    for pattern in patterns:
        if re.search(pattern, text):
            return True
    return False

def detect_generation_expressions(text):
    """Detecta express√µes sobre gera√ß√µes/idades"""
    text_lower = text.lower()
    
    patterns = [
        r'\b(gera√ß√£o|geracao)\b.*\b(fraca|fracassada|fracassado|nova|velha)\b',
        r'\b(fraca|fracassada|fracassado|nova|velha)\b.*\b(gera√ß√£o|geracao)\b',
        r'\b(gera√ß√£o|geracao)\b.*\b(perdida|sem futuro|sem rumo)\b'
    ]
    
    for pattern in patterns:
        if re.search(pattern, text_lower):
            return True
    return False

def detect_male_genital_machismo(text):
    """Detecta machismo atrav√©s de termos de genitais masculinos"""
    text_lower = text.lower()
    
    patterns = [
        r'\b(ovo|ovos|egg|eggs)\b.*\b(meu|minha|meus|minhas)\b',
        r'\b(roles|rola|pinto)\b.*\b(meu|minha|meus|minhas)\b',
        r'\b(meu|minha|meus|minhas)\b.*\b(ovo|ovos|egg|eggs|roles|rola|pinto)\b'
    ]
    
    for pattern in patterns:
        if re.search(pattern, text_lower):
            return True
    return False

def detect_clown_emoji_isolated(text):
    """Detecta emoji de palha√ßo isolado"""
    patterns = [
        r'^ü§°$',
        r'ü§°$',
        r'^ü§°'
    ]
    
    for pattern in patterns:
        if re.search(pattern, text):
            return True
    return False

def detect_care_expressions(text):
    """Detecta express√µes de cuidado/consolo"""
    text_lower = text.lower()
    
    patterns = [
        r'\b(vai|vai)\b.*\b(tomar|tomar)\b.*\b(rem√©dio|remedio)\b',
        r'\b(vai|vai)\b.*\b(dormir|descansar)\b',
        r'\b(cuide|cuida)\b.*\b(si|de si)\b',
        r'\b(descanse|descansa)\b'
    ]
    
    for pattern in patterns:
        if re.search(pattern, text_lower):
            return True
    return False

def detect_neutral_curse_words(text):
    """Detecta palavr√µes em contexto neutro"""
    text_lower = text.lower()
    
    patterns = [
        r'\b(fala|falar)\b.*\b(bosta|merda|porra)\b',
        r'\b(bosta|merda|porra)\b.*\b(fala|falar)\b',
        r'^bosta$',
        r'^merda$',
        r'^porra$'
    ]
    
    for pattern in patterns:
        if re.search(pattern, text_lower):
            return True
    return False

def detect_disapproval_without_hate(text):
    """Detecta express√µes de desaprova√ß√£o sem √≥dio"""
    text_lower = text.lower()
    
    patterns = [
        r'\b(palha√ßada|palhacada)\b',
        r'\b(pat√©tico|patetico)\b',
        r'\b(hilarious)\b',
        r'\b(rid√≠culo|ridiculo)\b'
    ]
    
    for pattern in patterns:
        if re.search(pattern, text_lower):
            return True
    return False

def detect_generic_insults_without_context(text):
    """Detecta insultos gen√©ricos sem contexto espec√≠fico"""
    text_lower = text.lower()
    
    patterns = [
        r'\b(analfabetos|analfabeto)\b.*\b(funcionais|funcional)\b',
        r'\b(retardades|retardado)\b',
        r'\b(vermes|verme)\b',
        r'\b(imbecis|imbecil)\b'
    ]
    
    for pattern in patterns:
        if re.search(pattern, text_lower):
            return True
    return False

def detect_neutral_emoji_context(text):
    """Detecta emojis em contexto neutro"""
    patterns = [
        r'üòÇ+.*\b(hilarious|engra√ßado|divertido)\b',
        r'\b(hilarious|engra√ßado|divertido)\b.*üòÇ+'
    ]
    
    for pattern in patterns:
        if re.search(pattern, text):
            return True
    return False

def detect_neutral_language_specific_cases(text):
    """Detecta casos espec√≠ficos de linguagem neutra"""
    text_lower = text.lower()
    
    patterns = [
        r'\btodes\b.*\b(meus|minhas)\b.*\b(ovos|ovo)\b.*\.\.',
        r'\b(meus|minhas)\b.*\b(ovos|ovo)\b.*\btodes\b.*\.\.'
    ]
    
    for pattern in patterns:
        if re.search(pattern, text_lower):
            return True
    return False

def detect_enhanced_male_genital_machismo(text):
    """Detecta machismo atrav√©s de genitais masculinos com alta prioridade"""
    text_lower = text.lower()
    
    # Padr√µes com possessivos masculinos
    possessive_patterns = [
        r'\b(meu|meus)\b.*\b(ovo|ovos|oves|egg|eggs)\b',
        r'\b(ovo|ovos|oves|egg|eggs)\b.*\b(meu|meus)\b',
        r'\b(meu|meus)\b.*\b(roles|rola|pinto|pintos)\b',
        r'\b(roles|rola|pinto|pintos)\b.*\b(meu|meus)\b'
    ]
    
    # Varia√ß√µes ortogr√°ficas (apenas quando em contexto de posse)
    spelling_variations = [
        r'\b(meuzovos|meusoves|meuzoves)\b',
        r'\b(oves|eggs)\b.*\b(meu|meus)\b',
        r'\b(meu|meus)\b.*\b(oves|eggs)\b',
        r'\b(roles|rola|pinto)\b.*\b(meu|meus)\b',
        r'\b(meu|meus)\b.*\b(roles|rola|pinto)\b'
    ]
    
    # Padr√µes em contexto de linguagem neutra
    neutral_language_context = [
        r'\btodes\b.*\b(meu|meus)\b.*\b(ovo|ovos|oves|egg|eggs)\b',
        r'\b(meu|meus)\b.*\b(ovo|ovos|oves|egg|eggs)\b.*\btodes\b',
        r'\btodes\b.*\b(roles|rola|pinto|pintos)\b',
        r'\b(roles|rola|pinto|pintos)\b.*\btodes\b'
    ]
    
    all_patterns = possessive_patterns + spelling_variations + neutral_language_context
    
    for pattern in all_patterns:
        if re.search(pattern, text_lower):
            return True
    return False

def detect_enhanced_neutral_language_hate(text):
    """Detecta √≥dio contra linguagem neutra - VERS√ÉO MELHORADA"""
    text_lower = text.lower()
    
    # Padr√µes de √≥dio espec√≠fico √† linguagem neutra (apenas quando em contexto de √≥dio)
    hate_neutral_language_patterns = [
        r'\b(que|que)\b.*\b(porcarie|porcarias)\b',
        r'\b(porcarie|porcarias)\b.*\b(que|que)\b',
        r'\b(todes|lules|mussum)\b.*\b(que|que)\b.*\b(porcarie|porcarias|nojento|escroto|desgra√ßado)\b',
        r'\b(que|que)\b.*\b(porcarie|porcarias)\b.*\b(todes|lules|mussum)\b',
        r'\b(modinha|frescura|babaquice)\b.*\b(todes|lules|linguagem neutra)\b',
        r'\b(todes|lules|linguagem neutra)\b.*\b(modinha|frescura|babaquice|idiota|burro)\b',
        r'\b(fim da picada|chega|basta)\b.*\b(todes|lules|linguagem neutra)\b',
        r'\b(todes|lules|linguagem neutra)\b.*\b(fim da picada|chega|basta|para)\b'
    ]
    
    all_patterns = hate_neutral_language_patterns
    
    for pattern in all_patterns:
        if re.search(pattern, text_lower):
            return True
    return False

# --- REGRAS CONTEXTUAIS PARA TERMOS LGBTQIA+ ---
def detect_positive_context(text):
    """Detecta contexto positivo para termos LGBTQIA+"""
    text_lower = text.lower()
    
    # Palavras positivas que indicam contexto de respeito/aceita√ß√£o
    positive_indicators = [
        'orgulho', 'pride', 'amor', 'love', 'respeito', 'respect',
        'beleza', 'beautiful', 'lindo', 'beautiful', 'maravilhoso', 'wonderful',
        'coragem', 'courage', 'for√ßa', 'strength', 'identidade', 'identity',
        'express√£o', 'expression', 'liberdade', 'freedom', 'direito', 'right',
        'aceitar', 'accept', 'aceitar', 'embrace', 'celebrar', 'celebrate',
        'apoio', 'support', 'solidariedade', 'solidarity', 'comunidade', 'community',
        'visibilidade', 'visibility', 'representa√ß√£o', 'representation',
        'diversidade', 'diversity', 'inclus√£o', 'inclusion', 'igualdade', 'equality'
    ]
    
    # Verificar se h√° indicadores positivos
    positive_count = sum(1 for indicator in positive_indicators if indicator in text_lower)
    
    return positive_count > 0

def detect_anatomical_reduction(text):
    """Detecta redu√ß√£o a genit√°lia (sempre hate)"""
    text_lower = text.lower()
    
    # Padr√µes de redu√ß√£o a genit√°lia
    anatomical_patterns = [
        'homem com buceta', 'mulher com p√™nis', 'p√™nis', 'buceta', 'vagina',
        'genit√°lia', 'genital', '√≥rg√£o sexual', 'parte √≠ntima',
        'tem que existir', 'deveria ter', 'deveria ser', '√© igual a',
        '√© s√≥', 'nada mais que', 'apenas', 'somente'
    ]
    
    # Verificar se h√° padr√µes de redu√ß√£o a genit√°lia
    for pattern in anatomical_patterns:
        if pattern in text_lower:
            return True
    
    return False

def detect_ridicule_context(text):
    """Detecta contexto de ridiculariza√ß√£o (sempre hate)"""
    text_lower = text.lower()
    
    # Padr√µes de ridiculariza√ß√£o
    ridicule_patterns = [
        'engra√ßado', 'engra√ßada', 'engra√ßad√≠ssimo', 'engra√ßad√≠ssima',
        'hil√°rio', 'hil√°ria', 'hilariante', 'c√¥mico', 'c√¥mica',
        'rid√≠culo', 'rid√≠cula', 'ridicularizar', 'zoar', 'zombar',
        'rir de', 'rindo de', 'risada', 'risadinha', 'piada',
        'brincadeira', 'brincar', 'zoa√ß√£o', 'zoeira',
        'achei engra√ßado', 'achei engra√ßada', 'engra√ßado esse', 'engra√ßada esse',
        'nome engra√ßado', 'termo engra√ßado', 'engra√ßado nome', 'engra√ßado termo'
    ]
    
    # Verificar se h√° padr√µes de ridiculariza√ß√£o
    for pattern in ridicule_patterns:
        if pattern in text_lower:
            return True
    
    return False

def detect_definition_context(text):
    """Detecta contexto de defini√ß√£o/educa√ß√£o (n√£o √© hate)"""
    text_lower = text.lower()
    
    # Padr√µes de defini√ß√£o/educa√ß√£o
    definition_patterns = [
        '√© uma', 'significa', 'quer dizer', 'defini√ß√£o', 'conceito',
        'explicar', 'entender', 'aprender', 'educar', 'informar',
        'pergunta', 'd√∫vida', 'curiosidade', 'interesse', 'pesquisa',
        'estudo', 'an√°lise', 'discuss√£o', 'debate', 'conversa',
        'simples', 'simplesmente', 'b√°sico', 'b√°sica', 'fundamental'
    ]
    
    # Verificar se h√° padr√µes de defini√ß√£o
    for pattern in definition_patterns:
        if pattern in text_lower:
            return True
    
    return False

def detect_legitimate_question_context(text):
    """Detecta contexto de pergunta leg√≠tima baseado no comprimento e estrutura"""
    text_lower = text.lower()
    
    # Contar palavras
    words = text.split()
    word_count = len(words)
    
    # Padr√µes de perguntas leg√≠timas
    question_patterns = [
        'pergunta', 'd√∫vida', 'curiosidade', 'interesse', 'pesquisa',
        'entender', 'aprender', 'explicar', 'significa', 'quer dizer',
        'como funciona', 'o que √©', 'pode explicar', 'tem como',
        'gostaria de saber', 'queria entender', 'preciso saber'
    ]
    
    # Padr√µes de cortesia e respeito
    courtesy_patterns = [
        'por favor', 'obrigado', 'obrigada', 'desculpe', 'desculpa',
        'com todo respeito', 'sem ofensa', 'sem hate', 'respeitosamente',
        'educadamente', 'gentilmente', 'cordialmente', 'entendi', 'obrigado pela',
        'obrigada pela', 'valeu', 'brigado', 'brigada'
    ]
    
    # Padr√µes de hesita√ß√£o e incerteza
    hesitation_patterns = [
        'acho que', 'creio que', 'talvez', 'possivelmente', 'provavelmente',
        'n√£o tenho certeza', 'n√£o sei', 'estou confuso', 'confuso',
        'n√£o entendi', 'n√£o compreendi', 'me explique'
    ]
    
    # Verificar padr√µes de pergunta leg√≠tima
    has_question_pattern = any(pattern in text_lower for pattern in question_patterns)
    has_courtesy_pattern = any(pattern in text_lower for pattern in courtesy_patterns)
    has_hesitation_pattern = any(pattern in text_lower for pattern in hesitation_patterns)
    
    # Textos longos (>15 palavras) com padr√µes de respeito/educa√ß√£o
    if word_count > 15 and (has_courtesy_pattern or has_hesitation_pattern):
        return True
    
    # Textos m√©dios (6-15 palavras) com padr√µes de pergunta ou cortesia
    if 6 <= word_count <= 15 and (has_question_pattern or has_courtesy_pattern):
        return True
    
    # Textos muito longos (>25 palavras) - provavelmente elabora√ß√£o leg√≠tima
    if word_count > 25:
        return True
    
    return False

def detect_short_aggressive_context(text):
    """Detecta contexto de √≥dio curto e agressivo"""
    text_lower = text.lower()
    
    # Contar palavras
    words = text.split()
    word_count = len(words)
    
    # Padr√µes de √≥dio direto e agressivo
    aggressive_patterns = [
        'odeio', 'detesto', 'nojo', 'asco', 'repugnante',
        'nojento', 'escroto', 'desgra√ßado', 'arrombado',
        'filho da puta', 'filha da puta', 'merda', 'porra',
        'caralho', 'puta', 'prostituta', 'vagabunda'
    ]
    
    # Padr√µes de amea√ßa e viol√™ncia
    threat_patterns = [
        'morrer', 'morra', 'mata', 'matar', 'eliminar',
        'destruir', 'acabar', 'sumir', 'desaparecer'
    ]
    
    # Padr√µes de rejei√ß√£o categ√≥rica
    rejection_patterns = [
        'nunca', 'jamais', 'nada', 'zero', 'nunca mais',
        'chega', 'basta', 'suficiente', 'acabou'
    ]
    
    # Verificar padr√µes agressivos
    has_aggressive_pattern = any(pattern in text_lower for pattern in aggressive_patterns)
    has_threat_pattern = any(pattern in text_lower for pattern in threat_patterns)
    has_rejection_pattern = any(pattern in text_lower for pattern in rejection_patterns)
    
    # Textos curtos (‚â§8 palavras) com padr√µes agressivos
    if word_count <= 8 and (has_aggressive_pattern or has_threat_pattern):
        return True
    
    # Textos muito curtos (‚â§5 palavras) com qualquer padr√£o negativo
    if word_count <= 5 and (has_aggressive_pattern or has_threat_pattern or has_rejection_pattern):
        return True
    
    return False

def detect_supportive_emojis(text):
    """Detecta emojis de apoio e suporte (n√£o √© hate)"""
    # Emojis de cora√ß√£o (apoio)
    heart_emojis = ['‚ù§Ô∏è', 'üß°', 'üíõ', 'üíö', 'üíô', 'üíú', 'üñ§', 'ü§ç', 'ü§é', 'üíï', 'üíñ', 'üíó', 'üíò', 'üíô', 'üíö', 'üíõ', 'üß°', '‚ù§Ô∏è']
    
    # Emojis trans e LGBTQIA+ (apoio)
    trans_emojis = ['üè≥Ô∏è‚Äç‚ößÔ∏è', 'üè≥Ô∏è‚Äçüåà', 'üè≥Ô∏è‚Äç‚ößÔ∏è', 'üè≥Ô∏è‚Äçüåà', '‚ößÔ∏è', 'üè≥Ô∏è‚Äç‚ößÔ∏è']
    
    # Emojis de fogo (apoio, quente)
    fire_emojis = ['üî•', 'üå∂Ô∏è', 'üå∂Ô∏è‚Äçüî•', 'üî•']
    
    # Emojis de apoio geral
    support_emojis = ['üëè', 'üôå', 'üí™', '‚ú®', 'üåü', '‚≠ê', 'üí´', 'üéâ', 'üéä', 'üåà', 'ü¶Ñ']
    
    # Verificar se h√° emojis de apoio
    for emoji in heart_emojis + trans_emojis + fire_emojis + support_emojis:
        if emoji in text:
            return True
    
    return False

def detect_mocking_emojis(text):
    """Detecta emojis de deboche e ridiculariza√ß√£o - VERS√ÉO MELHORADA"""
    text_lower = text.lower()
    
    # Emojis de deboche espec√≠fico (sempre hate)
    mocking_emojis = ['üôÑ', 'üòí', 'üò§', 'ü§®', 'üòë', 'üòê', 'üò∂', 'ü§ê', 'üò∑', 'ü§¢', 'ü§Æ']
    
    # Emojis de risada (s√≥ √© hate se acompanhado de contexto negativo)
    laugh_emojis = ['üòÇ', 'ü§£', 'üòÜ', 'üòÑ', 'üòÉ', 'üòä', 'üòã', 'üòú', 'üòù', 'ü§™', 'üòè', 'üòà']
    
    # Verificar emojis de deboche espec√≠fico
    for emoji in mocking_emojis:
        if emoji in text:
            return True
    
    # Para emojis de risada, verificar contexto
    has_laugh_emoji = any(emoji in text for emoji in laugh_emojis)
    
    if has_laugh_emoji:
        # Padr√µes de contexto negativo (S√ÉO hate com risada)
        negative_context_patterns = [
            r'\b(viado|bicha|sapat√£o|paneleiro|gay|lesbica|bissexual|queer|travesti|trans)\b.*\b(doente|nojento|escroto|desgra√ßado|de merda)\b',
            r'\b(que porra|que merda|que bosta|que droga)\b',
            r'\b(desgra√ßa|desgra√ßado|nojento|escroto|filho da puta)\b',
            r'\b(vai se foder|vai tomar no cu|vai pro inferno)\b',
            r'\b(odeio|detesto|repudio|rejeito)\b.*\b(lgbt|gay|lesbica|trans|queer)\b',
            r'\b(palha√ßada|palha√ßade|rid√≠culo|rid√≠cula|pat√©tico|pat√©tica)\b'
        ]
        
        # Verificar se h√° contexto negativo
        has_negative_context = any(re.search(pattern, text_lower) for pattern in negative_context_patterns)
        
        if has_negative_context:
            return True
    
    # Se n√£o tem emoji, n√£o √© mocking emoji
    return False

def detect_hate_emojis(text):
    """Detecta emojis de hate e √≥dio"""
    # Emojis de dem√¥nio (moral religiosa)
    demon_emojis = ['üòà', 'üëπ', 'üë∫', 'üíÄ', '‚ò†Ô∏è', 'üëª', 'üé≠']
    
    # Emojis de v√¥mito e coc√¥ (hate)
    disgust_emojis = ['ü§Æ', 'ü§¢', 'üí©', 'ü™£', 'üöΩ', 'üßª']
    
    # Emojis de morte e viol√™ncia
    violence_emojis = ['üíÄ', '‚ò†Ô∏è', 'üî™', 'üó°Ô∏è', '‚öîÔ∏è', 'üî´', 'üí£', 'üß®', 'üí•', 'üí¢', 'üíÄ']
    
    # Verificar se h√° emojis de hate
    for emoji in demon_emojis + disgust_emojis + violence_emojis:
        if emoji in text:
            return True
    
    return False

def detect_text_mocking_patterns(text):
    """Detecta padr√µes de texto que indicam deboche - VERS√ÉO MELHORADA"""
    text_lower = text.lower()
    
    # Padr√µes de risada em texto (apenas quando acompanhados de contexto negativo)
    laugh_patterns = [
        'kkkk', 'kkkkk', 'kkkkkk', 'kkkkkkk', 'kkkkkkkk',
        'hahaha', 'hahahaha', 'hehehe', 'hehehehe',
        'rsrsrs', 'rsrsrsrs', 'huehue', 'huehuehue',
        'lol', 'lmao', 'rofl', 'hahah', 'heheh'
    ]
    
    # Verificar se h√° padr√µes de risada
    has_laugh_pattern = any(pattern in text_lower for pattern in laugh_patterns)
    
    if not has_laugh_pattern:
        return False
    
    # Padr√µes de contexto negativo (S√ÉO hate com risada)
    negative_context_patterns = [
        r'\b(viado|bicha|sapat√£o|paneleiro|gay|lesbica|bissexual|queer|travesti|trans)\b.*\b(doente|nojento|escroto|desgra√ßado|de merda)\b',
        r'\b(que porra|que merda|que bosta|que droga)\b',
        r'\b(desgra√ßa|desgra√ßado|nojento|escroto|filho da puta)\b',
        r'\b(vai se foder|vai tomar no cu|vai pro inferno)\b',
        r'\b(odeio|detesto|repudio|rejeito)\b.*\b(lgbt|gay|lesbica|trans|queer)\b',
        r'\b(palha√ßada|palha√ßade|rid√≠culo|rid√≠cula|pat√©tico|pat√©tica)\b'
    ]
    
    # Verificar se h√° contexto negativo
    has_negative_context = any(re.search(pattern, text_lower) for pattern in negative_context_patterns)
    
    # S√≥ √© hate se h√° risada E contexto negativo
    return has_negative_context

def detect_condescending_commands(text):
    """Detecta comandos condescendentes (geralmente hate)"""
    text_lower = text.lower()
    
    # Padr√µes de comandos condescendentes
    condescending_patterns = [
        'vai estudar', 'vai trabalhar', 'vai trabalhar', 'vai estudar',
        'vai procurar o que fazer', 'vai arrumar o que fazer',
        'vai cuidar da sua vida', 'vai se ocupar',
        'vai ler um livro', 'vai se informar',
        'vai fazer algo √∫til', 'vai ser √∫til',
        'vai se tratar', 'vai se cuidar',
        'vai procurar ajuda', 'vai se tratar'
    ]
    
    # Verificar se h√° padr√µes condescendentes
    for pattern in condescending_patterns:
        if pattern in text_lower:
            return True
    
    return False

def detect_religious_moralism(text):
    """Detecta moralismo religioso (geralmente hate)"""
    text_lower = text.lower()
    
    # Termos religiosos que geralmente indicam moralismo
    religious_terms = [
        'jesus', 'pai', 'deus', 'senhor', 'cristo',
        'sagrado', 'santo', 'aben√ßoado', 'aben√ßoada',
        'pecado', 'pecador', 'pecadora', 'condenado', 'condenada',
        'inferno', 'dem√¥nio', 'satan√°s', 'maldito', 'maldita',
        'amaldi√ßoado', 'amaldi√ßoada', 'castigo', 'puni√ß√£o',
        'apocalipse', 'revela√ß√£o', 'profecia', 'b√≠blia',
        'igreja', 'pastor', 'padre', 'bispo', 'arcebispo'
    ]
    
    # Verificar se h√° termos religiosos
    for term in religious_terms:
        if term in text_lower:
            return True
    
    return False

def detect_pathologizing_terms(text):
    """Detecta termos que patologizam (geralmente hate)"""
    text_lower = text.lower()
    
    # Termos m√©dicos que geralmente patologizam
    pathologizing_terms = [
        'psiquiatra', 'urologista', 'ginecologista', 'psicologo',
        'psic√≥logo', 'terapeuta', 'analista', 'm√©dico',
        'doutor', 'doutora', 'cl√≠nica', 'hospital',
        'tratamento', 'terapia', 'medicamento', 'rem√©dio',
        'doen√ßa', 'doente', 'patologia', 's√≠ndrome',
        'dist√∫rbio', 'transtorno', 'desvio', 'anormalidade'
    ]
    
    # Verificar se h√° termos patologizantes
    for term in pathologizing_terms:
        if term in text_lower:
            return True
    
    return False

def detect_disguised_hate(text):
    """Detecta hate disfar√ßado com pontos, n√∫meros, etc. - VERS√ÉO MELHORADA"""
    text_lower = text.lower()
    
    # Padr√µes de hate disfar√ßado (apenas casos √≥bvios de hate)
    disguised_hate_patterns = [
        'ri di cu', 'r1 d1 c0', 'r1 d1 c0', 'r1 d1 c0',
        'viado do caralho', 'bicha nojenta', 'sapat√£o desgra√ßada', 'paneleiro de merda',
        'gay de merda', 'l√©sbica nojenta', 'bissexual escrota', 'queer desgra√ßado',
        'travesti nojenta', 'trans doente', 'lgbt de merda', 'lgbtqia escrota'
    ]
    
    # Padr√µes de contexto positivo (N√ÉO s√£o hate)
    positive_context_patterns = [
        r'\b(meu|minha|nosso|nossa)\b.*\b(bar|restaurante|local|lugar|favorito|preferido)\b',
        r'\b(amo|adoro|gosto|aprecio|respeito|apoio|defendo)\b',
        r'\b(orgulho|pride|diversidade|inclus√£o|igualdade)\b',
        r'\b(comunidade|grupo|coletivo|movimento)\b',
        r'\b(direitos|direito de ser|viv√™ncia|identidade)\b',
        r'\b(visibilidade|representa√ß√£o|aceita√ß√£o|toler√¢ncia)\b',
        r'\b(pode sim|pode continuar|uma coisa n impede|n√£o impede)\b',
        r'\b(diagn√≥stico|abriu|inclusive|correlato)\b',
        r'\b(entendi|entendendo|compreendo|compreendendo)\b',
        r'\b(sapat√£o|gay|lesbica|bissexual|queer|travesti|trans)\b.*\b(favorito|preferido|legal|bom|√≥timo)\b',
        r'\b(bar|restaurante|local|lugar)\b.*\b(sapat√£o|gay|lesbica|bissexual|queer|travesti|trans)\b'
    ]
    
    # Verificar se h√° padr√µes de hate disfar√ßado
    has_disguised_hate = any(pattern in text_lower for pattern in disguised_hate_patterns)
    
    # Verificar se h√° contexto positivo
    has_positive_context = any(re.search(pattern, text_lower) for pattern in positive_context_patterns)
    
    # Se tem contexto positivo, N√ÉO √© hate
    if has_positive_context:
        return False
    
    # Se tem padr√£o de hate disfar√ßado, √© hate
    if has_disguised_hate:
        return True
    
    # Verificar termos LGBTQIA+ isolados (sem contexto positivo)
    lgbtqia_terms = ['viado', 'bicha', 'sapat√£o', 'paneleiro', 'gay', 'l√©sbica', 'bissexual', 'queer', 'travesti', 'trans', 'lgbt', 'lgbtqia']
    
    # Contar quantos termos LGBTQIA+ existem
    lgbtqia_count = sum(1 for term in lgbtqia_terms if term in text_lower)
    
    # Se h√° muitos termos LGBTQIA+ sem contexto positivo, pode ser hate
    if lgbtqia_count >= 2:
        return True
    
    # Se h√° apenas 1 termo LGBTQIA+ sem contexto positivo, verificar se √© usado de forma negativa
    if lgbtqia_count == 1:
        # Padr√µes que indicam uso negativo
        negative_patterns = [
            r'\b(odeio|detesto|nojento|repugnante|asqueroso)\b',
            r'\b(doente|doen√ßa|tratamento|cura|psicol√≥gico|mental)\b',
            r'\b(pecado|deus|dem√¥nio|igreja|b√≠blia|crist√£o)\b',
            r'\b(natural|normal|anormal|aberra√ß√£o|erro)\b',
            r'\b(filho da puta|filha da puta|arrombado|escroto|desgra√ßado)\b'
        ]
        
        # Se h√° padr√µes negativos, √© hate
        if any(re.search(pattern, text_lower) for pattern in negative_patterns):
            return True
    
    return False

def detect_shame_terms(text):
    """Detecta termos de vergonha (geralmente hate)"""
    text_lower = text.lower()
    
    # Termos de vergonha
    shame_terms = [
        'vergonha', 'vergonhoso', 'vergonhosa', 'vergonhoso',
        'envergonhado', 'envergonhada', 'envergonhado',
        'sem vergonha', 'sem-vergonha', 'semvergonha',
        'desvergonhado', 'desvergonhada', 'desvergonhado',
        'atrevido', 'atrevida', 'atrevido',
        'ousado', 'ousada', 'ousado'
    ]
    
    # Verificar se h√° termos de vergonha
    for term in shame_terms:
        if term in text_lower:
            return True
    
    return False

def detect_curse_words(text):
    """Detecta palavr√µes (geralmente hate)"""
    text_lower = text.lower()
    
    # Palavr√µes
    curse_words = [
        'bosta', 'merda', 'porra', 'caralho', 'puta',
        'filho da puta', 'filha da puta', 'arrombado',
        'arrombada', 'escroto', 'escrota', 'nojento',
        'nojenta', 'desgra√ßado', 'desgra√ßada', 'lixo',
        'lix√£o', 'sujo', 'suja', 'fedido', 'fedida'
    ]
    
    # Verificar se h√° palavr√µes
    for word in curse_words:
        if word in text_lower:
            return True
    
    return False

def detect_misogynistic_terms(text):
    """Detecta termos machistas (geralmente hate)"""
    text_lower = text.lower()
    
    # Termos machistas
    misogynistic_terms = [
        'lavar lou√ßa', 'vai lavar lou√ßa', 'cozinha', 'vai cozinhar',
        'roupa', 'vai passar roupa', 'limpeza', 'vai limpar',
        'casa', 'vai cuidar da casa', 'filhos', 'vai cuidar dos filhos',
        'mulher', 'sua mulher', 'esposa', 'sua esposa',
        'm√£e', 'sua m√£e', 'av√≥', 'sua av√≥'
    ]
    
    # Verificar se h√° termos machistas
    for term in misogynistic_terms:
        if term in text_lower:
            return True
    
    return False

def detect_condescending_metaphors(text):
    """Detecta met√°foras condescendentes (geralmente hate)"""
    text_lower = text.lower()
    
    # Met√°foras condescendentes
    condescending_metaphors = [
        'um lote', 'capinar um lote', 'vai capinar um lote',
        'plantar', 'vai plantar', 'semeiar', 'vai semear',
        'colher', 'vai colher', 'cavar', 'vai cavar',
        'construir', 'vai construir', 'trabalhar', 'vai trabalhar',
        'servir', 'vai servir', 'obedecer', 'vai obedecer'
    ]
    
    # Verificar se h√° met√°foras condescendentes
    for metaphor in condescending_metaphors:
        if metaphor in text_lower:
            return True
    
    return False

def detect_condescending_insults(text):
    """Detecta insultos condescendentes (geralmente hate)"""
    text_lower = text.lower()
    
    # Insultos condescendentes
    condescending_insults = [
        'desempregado', 'desempregada', 'vagabundo', 'vagabunda',
        'pregui√ßoso', 'pregui√ßosa', 'in√∫til', 'in√∫til',
        'burro', 'burra', 'idiota', 'imbecil',
        'est√∫pido', 'est√∫pida', 'estupidez', 'burrice',
        'ignorante', 'analfabeto', 'analfabeta', 'inculto', 'inculta'
    ]
    
    # Verificar se h√° insultos condescendentes
    for insult in condescending_insults:
        if insult in text_lower:
            return True
    
    return False

def detect_excessive_punctuation(text):
    """Detecta excessos de pontua√ß√£o (geralmente hate) - VERS√ÉO MELHORADA"""
    text_lower = text.lower()
    
    # Contar exclama√ß√µes e interroga√ß√µes
    exclamation_count = text.count('!')
    question_count = text.count('?')
    
    # Padr√µes de contexto positivo (N√ÉO s√£o hate mesmo com pontua√ß√£o excessiva)
    positive_context_patterns = [
        r'\b(que legal|que bom|que √≥timo|que incr√≠vel|que maravilhoso)\b',
        r'\b(parab√©ns|parab√©ns|felicita√ß√µes|congratulations)\b',
        r'\b(amo|adoro|gosto|aprecio|respeito|apoio|defendo)\b',
        r'\b(orgulho|pride|diversidade|inclus√£o|igualdade)\b',
        r'\b(conforto|tranquilidade|paz|alegria|felicidade)\b',
        r'\b(meu amor|minha amor|amor)\b',
        r'\b(seja feliz|feliz sempre|seja o que voc√™ quiser)\b',
        r'\b(obrigada|obrigado|thanks|thank you)\b',
        r'\b(incr√≠vel|maravilhoso|fant√°stico|√≥timo|excelente)\b',
        r'\b(amei|adoro|gostei|curti|aprovei)\b'
    ]
    
    # Padr√µes de contexto negativo (S√ÉO hate com pontua√ß√£o excessiva)
    negative_context_patterns = [
        r'\b(viado|bicha|sapat√£o|paneleiro|gay|lesbica|bissexual|queer|travesti|trans)\b.*\b(doente|nojento|escroto|desgra√ßado|de merda)\b',
        r'\b(que porra|que merda|que bosta|que droga)\b',
        r'\b(desgra√ßa|desgra√ßado|nojento|escroto|filho da puta)\b',
        r'\b(vai se foder|vai tomar no cu|vai pro inferno)\b',
        r'\b(odeio|detesto|repudio|rejeito)\b.*\b(lgbt|gay|lesbica|trans|queer)\b'
    ]
    
    # Verificar se h√° contexto positivo
    has_positive_context = any(re.search(pattern, text_lower) for pattern in positive_context_patterns)
    
    # Verificar se h√° contexto negativo
    has_negative_context = any(re.search(pattern, text_lower) for pattern in negative_context_patterns)
    
    # Se tem contexto positivo, N√ÉO √© hate
    if has_positive_context:
        return False
    
    # Se tem contexto negativo, √© hate
    if has_negative_context:
            return True
    
    # S√≥ considerar hate se h√° pontua√ß√£o excessiva E contexto negativo
    # Pontua√ß√£o excessiva sozinha n√£o √© hate
    return False

def detect_direct_insults(text):
    """Detecta insultos diretos (geralmente hate)"""
    text_lower = text.lower()
    
    # Insultos diretos
    direct_insults = [
        'pat√©tico', 'pat√©tica', 'rid√≠culo', 'rid√≠cula',
        'nojento', 'nojenta', 'repugnante', 'asqueroso', 'asquerosa',
        'desprez√≠vel', 'vergonhoso', 'vergonhosa', 'humilhante',
        'ofensivo', 'ofensiva', 'agressivo', 'agressiva',
        'violento', 'violenta', 'brutal', 'cruel'
    ]
    
    # Verificar se h√° insultos diretos
    for insult in direct_insults:
        if insult in text_lower:
            return True
    
    return False

def detect_negative_context(text):
    """Detecta contexto negativo para termos LGBTQIA+"""
    text_lower = text.lower()
    
    # Palavras negativas que indicam contexto de √≥dio/rejei√ß√£o
    negative_indicators = [
        '√≥dio', 'hate', 'nojo', 'disgust', 'repugnante', 'repugnant',
        'nojento', 'disgusting', 'escroto', 'disgusting', 'desgra√ßado', 'damned',
        'arrombado', 'fucked', 'merda', 'shit', 'caralho', 'fuck',
        'filho da puta', 'son of a bitch', 'filha da puta', 'daughter of a bitch',
        'doente', 'sick', 'anormal', 'abnormal', 'errado', 'wrong',
        'pecado', 'sin', 'dem√¥nio', 'devil', 'inferno', 'hell',
        'morte', 'death', 'morrer', 'die', 'matar', 'kill',
        'eliminar', 'eliminate', 'destruir', 'destroy', 'acabar',
        # Adicionar mais indicadores negativos espec√≠ficos
        'nojenta', 'escrota', 'desgra√ßada', 'arrombada', 'merdosa', 'caralhosa',
        'filha da puta', 'puta', 'prostituta', 'vagabunda', 'safada',
        'doen√ßa', 'doente', 'anormal', 'errado', 'pecado', 'dem√¥nio',
        'inferno', 'morte', 'morrer', 'matar', 'eliminar', 'destruir'
    ]
    
    # Verificar se h√° indicadores negativos
    negative_count = sum(1 for indicator in negative_indicators if indicator in text_lower)
    
    return negative_count > 0

def contextual_gender_dissidence_rule(text):
    """Regra contextual para termos de dissid√™ncia de g√™nero"""
    text_lower = text.lower()
    
    # Termos de dissid√™ncia de g√™nero que podem ser positivos ou negativos
    gender_dissidence_terms = [
        'boyceta', 'boycet', 'sapat√£o', 'travesti', 'transg√™nero', 'transgenero',
        'n√£o-bin√°rio', 'nao-binario', 'genderqueer', 'queer',
        'drag queen', 'drag king', 'crossdresser'
    ]
    
    # Verificar se h√° termos de dissid√™ncia de g√™nero
    has_gender_term = any(term in text_lower for term in gender_dissidence_terms)
    
    if not has_gender_term:
        return None
    
    # 1. PRIMEIRO: Verificar emojis de hate (sempre hate)
    # Esta tem prioridade m√°xima para detectar √≥dio expl√≠cito
    if detect_hate_emojis(text):
        return "hate"
    
    # 2. SEGUNDO: Verificar emojis de apoio (n√£o √© hate)
    # Esta tem prioridade alta para proteger apoio leg√≠timo
    if detect_supportive_emojis(text):
        return "n√£o_hate"
    
    # 3. TERCEIRO: Verificar contexto de pergunta leg√≠tima (n√£o √© hate)
    if detect_legitimate_question_context(text):
        return "n√£o_hate"
    
    # 4. QUARTO: Verificar contexto de defini√ß√£o/educa√ß√£o (n√£o √© hate)
    if detect_definition_context(text):
        return "n√£o_hate"
    
    # 5. QUINTO: Verificar √≥dio curto e agressivo (sempre hate)
    if detect_short_aggressive_context(text):
        return "hate"
    
    # 6. SEXTO: Verificar ridiculariza√ß√£o (sempre hate)
    if detect_ridicule_context(text):
        return "hate"
    
    # 7. S√âTIMO: Verificar redu√ß√£o a genit√°lia (sempre hate)
    if detect_anatomical_reduction(text):
        return "hate"
    
    # 8. OITAVO: Verificar emojis de deboche (poss√≠vel hate)
    if detect_mocking_emojis(text) or detect_text_mocking_patterns(text):
        return "hate"
    
    # 9. NONO: Detectar contexto positivo/negativo
    is_positive = detect_positive_context(text)
    is_negative = detect_negative_context(text)
    
    # Se h√° contexto positivo e n√£o h√° contexto negativo ‚Üí n√£o √© hate
    if is_positive and not is_negative:
        return "n√£o_hate"
    
    # Se h√° contexto negativo ‚Üí √© hate
    if is_negative:
        return "hate"
    
    # Se n√£o h√° contexto claro, usar regras espec√≠ficas
    return None

def specific_gender_terms_rule(text):
    """Regra espec√≠fica para termos de g√™nero problem√°ticos"""
    text_lower = text.lower()
    
    # Termos espec√≠ficos que precisam de an√°lise cuidadosa
    problematic_terms = {
        'boyceta': {
            'positive_contexts': ['orgulho', 'beleza', 'identidade', 'express√£o'],
            'negative_contexts': ['nojento', 'escroto', 'desgra√ßado', 'arrombado']
        },
        'sapat√£o': {
            'positive_contexts': ['orgulho', 'for√ßa', 'coragem', 'identidade'],
            'negative_contexts': ['nojento', 'escroto', 'desgra√ßado', 'arrombado']
        },
        'travesti': {
            'positive_contexts': ['orgulho', 'beleza', 'identidade', 'express√£o'],
            'negative_contexts': ['nojento', 'escroto', 'desgra√ßado', 'arrombado']
        }
    }
    
    for term, contexts in problematic_terms.items():
        if term in text_lower:
            # Verificar contexto positivo
            positive_found = any(ctx in text_lower for ctx in contexts['positive_contexts'])
            # Verificar contexto negativo
            negative_found = any(ctx in text_lower for ctx in contexts['negative_contexts'])
            
            # Se h√° contexto positivo e n√£o h√° negativo ‚Üí n√£o √© hate
            if positive_found and not negative_found:
                return "n√£o_hate"
            
            # Se h√° contexto negativo ‚Üí √© hate
            if negative_found:
                return "hate"
    
    return None

def enhanced_hybrid_rules(text):
    """Regras h√≠bridas aprimoradas com contexto de g√™nero"""
    
    # 1. Primeiro: verificar contexto de dissid√™ncia de g√™nero
    gender_result = contextual_gender_dissidence_rule(text)
    if gender_result:
        return gender_result
    
    # 2. Segundo: verificar termos espec√≠ficos problem√°ticos
    specific_result = specific_gender_terms_rule(text)
    if specific_result:
        return specific_result
    
    # 3. Terceiro: aplicar regras originais de insulto
    text_lower = text.lower()
    
    # Padr√£o: [termo LGBTQIA+] + [insulto]
    insult_patterns = [
        'filho da puta', 'filha da puta', 'arrombado', 'arrombada',
        'escroto', 'escrota', 'nojento', 'nojenta', 'desgra√ßado', 'desgra√ßada',
        'de merda', 'do caralho', 'filho da puta', 'filha da puta'
    ]
    
    lgbtqia_terms = ['viado', 'bicha', 'gay', 'l√©sbica', 'bissexual', 'queer']
    
    # Se h√° termo LGBTQIA+ + insulto ‚Üí FOR√áAR ass√©dio
    if any(term in text_lower for term in lgbtqia_terms) and \
       any(insult in text_lower for insult in insult_patterns):
        return "assedio_insulto"
    
    return None

# --- Fun√ß√£o para Detectar Falsos Positivos ---
def has_positive_adjective(text):
    """Verifica se o texto cont√©m adjetivos positivos"""
    positive_adjectives = [
        'del√≠cia', 'maravilhoso', 'lindo', 'bonito', 'incr√≠vel', 'fant√°stico',
        'perfeito', '√≥timo', 'excelente', 'magn√≠fico', 'espl√™ndido', 'formid√°vel',
        'ador√°vel', 'encantador', 'fabuloso', 'sensacional', 'extraordin√°rio',
        'divino', 'celestial', 'majestoso', 'sublime', 'extraordin√°rio'
    ]
    
    normalized = normalize_text(text)
    return any(adj in normalized for adj in positive_adjectives)

def is_lgbtqia_pattern(text):
    """Verifica se segue o padr√£o 'ser [termo LGBTQIA+] √© [adjetivo]'"""
    lgbtqia_terms = [
        'gay', 'l√©sbica', 'trans', 'bicha', 'viado', 'sapat√£o', 'paneleiro', 'paneleira',
        'travesti', 'lgbt', 'lgbtqia', 'queer', 'homossexual', 'bissexual', 'pansexual',
        'assexual', 'n√£o-bin√°rio', 'intersexo', 'transg√™nero', 'transexual'
    ]
    
    normalized = normalize_text(text)
    
    # Padr√£o: ser [termo] √© [algo]
    pattern = r'ser\s+(\w+)\s+√©\s+(.+)'
    match = re.search(pattern, normalized)
    
    if match:
        term = match.group(1)
        return term in lgbtqia_terms
    
    return False

# --- Carregamento dos Modelos Reais ---
print("üîÑ Carregando modelos reais...")

try:
    # Carregar modelo bin√°rio (usando subpasta)
    print("üì¶ Carregando modelo bin√°rio...")
    tokenizer_binary = AutoTokenizer.from_pretrained(MODEL_PATH, subfolder="model-binary-expanded-with-toldbr")
    model_binary = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, subfolder="model-binary-expanded-with-toldbr")
    
    # Carregar modelo especializado (usando subpasta)
    print("üì¶ Carregando modelo especializado...")
    tokenizer_specialized = AutoTokenizer.from_pretrained(MODEL_PATH, subfolder="model-specialized-expanded")
    model_specialized = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, subfolder="model-specialized-expanded")
    
    print("‚úÖ Modelos ensemble corretos carregados com sucesso!")
    
except Exception as e:
    print(f"‚ö†Ô∏è Erro ao carregar modelos: {e}")
    print("üîÑ Usando sistema de fallback...")
    
    # Fallback para sistema de palavras-chave
    def simulate_hate_detection(text):
        text_lower = text.lower()
        lgbtqia_words = ['gay', 'l√©sbica', 'bicha', 'viado', 'sapat√£o', 'paneleiro', 'paneleira', 
                         'travesti', 'trans', 'lgbt', 'lgbtqia', 'queer', 'faggot', 'dyke', 'tranny']
        hate_words = ['morrer', 'morra', 'mata', 'matar', 'odeio', 'odeia', 'detesto', 'detesta',
                      'vergonha', 'nojo', 'asco', 'repugnante', 'nojento', 'abomin√°vel',
                      'odio', '√≥dio', 'lixo', 'desgra√ßa', 'maldito', 'anormal', 'doente']
        insult_words = ['merda', 'porra', 'caralho', 'puta', 'filho da puta', 'desgra√ßa', 
                       'esc√≥ria', 'nojento', 'abomina√ß√£o', 'vergonha', 'doen√ßa']
        religious_words = ['pecado', 'pecador', 'condenado', 'inferno', 'dem√¥nio', 'satan√°s', 
                          'maldito', 'amaldi√ßoado']
        
        hate_patterns = [
            lambda t: any(word in t for word in lgbtqia_words) and any(phrase in t for phrase in ['deveria morrer', 'deveria morre', 'deveria morr', 'deveria mor', 'deveria mo', 'deveria m', 'deveria']),
            lambda t: any(word in t for word in lgbtqia_words) and any(word in t for word in ['de merda', 'merda']),
            lambda t: any(word in t for word in lgbtqia_words) and any(word in t for word in ['√© pecado', 'pecado', 'pecador']),
            lambda t: any(word in t for word in hate_words),
            lambda t: any(word in t for word in lgbtqia_words) and any(word in t for word in insult_words),
            lambda t: any(word in t for word in lgbtqia_words) and any(word in t for word in religious_words),
        ]
        
        is_hate = False
        hate_prob = 0.1
        specialized_class = "N/A"
        
        for i, pattern in enumerate(hate_patterns):
            if pattern(text_lower):
                is_hate = True
                hate_prob = min(0.7 + (i * 0.05), 0.95)
                if i == 0:
                    specialized_class = "Amea√ßa/Viol√™ncia"
                elif i == 1:
                    specialized_class = "Ass√©dio/Insulto"
                elif i == 2:
                    specialized_class = "√ìdio Religioso"
                elif any(word in text_lower for word in ['trans', 'travesti', 'tranny']):
                    specialized_class = "Transfobia"
                else:
                    specialized_class = "Ass√©dio/Insulto"
                break
        
        if not is_hate:
            lgbtqia_count = sum(1 for word in lgbtqia_words if word in text_lower)
            hate_count = sum(1 for word in hate_words if word in text_lower)
            insult_count = sum(1 for word in insult_words if word in text_lower)
            if lgbtqia_count > 0 and (hate_count > 0 or insult_count > 0):
                is_hate = True
                hate_prob = min(0.6 + (lgbtqia_count + hate_count + insult_count) * 0.1, 0.9)
                specialized_class = "Ass√©dio/Insulto"
        
        return {
            'is_hate': is_hate,
            'hate_probability': hate_prob,
            'specialized_class': specialized_class,
            'confidence': max(hate_prob, 1-hate_prob)
        }

# --- Fun√ß√£o de Predi√ß√£o com Regras Contextuais ---
def detect_positive_context_with_emojis(text):
    """Detecta contexto positivo com emojis de apoio"""
    text_lower = text.lower()
    
    # Emojis de apoio e positividade
    positive_emojis = ['‚ù§Ô∏è', 'üíñ', 'üíï', 'üíó', 'üíù', 'üíò', 'üíû', 'üíü', '‚ô•Ô∏è', 'üíú', 'üíô', 'üíö', 'üíõ', 'üß°', 'ü§ç', 'üñ§', 'ü§é', 'üíØ', '‚ú®', 'üåü', '‚≠ê', 'üí´', 'üåà', 'ü¶Ñ', 'üëè', 'üôå', 'üëç', 'üëå', 'ü§ù', 'ü§ó', 'ü§≤', 'üôè', 'üí™', 'üéâ', 'üéä', 'üéà', 'üéÅ', 'üèÜ', 'ü•á', 'ü•∞', 'üòç', 'ü•∫', 'üòä', 'üòá', 'üòå', 'üòã', 'ü§§', 'üòò', 'üòó', 'üòô', 'üòö', 'üò∏', 'üòπ', 'üò∫', 'üòª', 'üòº', 'üòΩ', 'üôÄ', 'üòø', 'üòæ']
    
    # Padr√µes de positividade
    positive_patterns = [
        r'\b(obrigada|obrigado|obrigad[ao])\b',
        r'\b(amo|adoro|gosto|aprecio|respeito|apoio|defendo)\b',
        r'\b(orgulho|pride|diversidade|inclus√£o|igualdade)\b',
        r'\b(conforto|tranquilidade|paz|alegria|felicidade)\b',
        r'\b(n√£o t√¥ sozinha|n√£o estou sozinha|n√£o estou sozinho|n√£o t√¥ sozinho)\b'
    ]
    
    # Verificar emojis positivos
    has_positive_emoji = any(emoji in text for emoji in positive_emojis)
    
    # Verificar padr√µes positivos
    has_positive_pattern = any(re.search(pattern, text_lower) for pattern in positive_patterns)
    
    return has_positive_emoji and has_positive_pattern

def detect_neutral_language_only(text):
    """Detecta se √© apenas linguagem neutra sozinha (N√ÉO √© hate)"""
    text_lower = text.lower().strip()
    
    # Palavras de linguagem neutra sozinhas
    neutral_words = ['todes', 'lules', 'mussum', 'elu', 'delu', 'nelu', 'aquelu', 'daquelu']
    
    # Verificar se √© apenas uma palavra de linguagem neutra
    if text_lower in neutral_words:
        return True
    
    # Verificar se s√£o apenas palavras de linguagem neutra separadas por espa√ßo
    words = text_lower.split()
    if len(words) <= 3 and all(word in neutral_words for word in words):
        return True
    
    return False

def detect_single_emoji_context(text):
    """Detecta se √© apenas um emoji sozinho ou com contexto m√≠nimo"""
    text_stripped = text.strip()
    
    # Emojis que sozinhos n√£o devem ser hate (apenas neutros)
    neutral_single_emojis = ['üòë', 'üòê', 'üò∂', 'ü§ê', 'üò∑', 'ü§î', 'üòï', 'üòü', 'üòî', 'üòû', 'üò¢', 'üò≠']
    
    # Emojis de hate que N√ÉO devem ser considerados neutros
    hate_emojis = ['üò§', 'üò†', 'üò°', 'ü§¨', 'üòà', 'üëø', '0', '‚ò†Ô∏è', 'üëª']
    
    # Se tem emoji de hate, N√ÉO √© contexto neutro
    if any(emoji in text for emoji in hate_emojis):
        return False
    
    # Se √© apenas um emoji neutro
    if len(text_stripped) <= 3 and any(emoji in text_stripped for emoji in neutral_single_emojis):
        return True
    
    # Se √© emoji neutro + texto muito curto (ex: "üòë" ou "O √≥bvio precisa ser dito üòë")
    if len(text_stripped) <= 50 and any(emoji in text_stripped for emoji in neutral_single_emojis):
        return True
    
    return False

def detect_orgulho_lgbtqia(text):
    """Detecta padr√µes de orgulho LGBTQIA+"""
    text_lower = text.lower()
    
    # Padr√µes de orgulho LGBTQIA+
    orgulho_patterns = [
        r'\b(com muito orgulho|com orgulho|sou orgulhoso|sou orgulhosa)\b',
        r'\b(me orgulho|orgulho de ser|orgulho de mim|orgulho da minha)\b',
        r'\b(sou sapat√£o|sou gay|sou l√©sbica|sou bissexual|sou queer)\b',
        r'\b(sou trans|sou travesti|sou transg√™nero|sou transgenero)\b',
        r'\b(orgulho lgbt|orgulho lgbtqia|pride|diversidade)\b'
    ]
    
    return any(re.search(pattern, text_lower) for pattern in orgulho_patterns)

def detect_respeito_aceitacao(text):
    """Detecta padr√µes de respeito e aceita√ß√£o"""
    text_lower = text.lower()
    
    # Padr√µes de respeito e aceita√ß√£o
    respeito_patterns = [
        r'\b(respeitar|respeito|aceitar|aceita√ß√£o|toler√¢ncia)\b',
        r'\b(diversidade|inclus√£o|igualdade|direitos|direito de ser)\b',
        r'\b(viv√™ncia pessoal|viv√™ncia deve ser respeitada)\b',
        r'\b(empatia e o respeito|respeito n√£o pode ser seletivos)\b',
        r'\b(promover um debate de respeito)\b'
    ]
    
    return any(re.search(pattern, text_lower) for pattern in respeito_patterns)

def detect_curse_words_positive_context(text):
    """Detecta palavr√µes em contexto positivo"""
    text_lower = text.lower()
    
    # Palavr√µes comuns
    curse_words = ['caralho', 'porra', 'merda', 'bosta', 'puta', 'foda']
    
    # Padr√µes de contexto positivo
    positive_context_patterns = [
        r'\b(obrigada|obrigado|obrigad[ao])\b',
        r'\b(conforto|tranquilidade|paz|alegria|felicidade)\b',
        r'\b(n√£o t√¥ sozinha|n√£o estou sozinha|n√£o estou sozinho|n√£o t√¥ sozinho)\b',
        r'\b(gente|pessoas|amigos|amigas)\b'
    ]
    
    has_curse_word = any(curse in text_lower for curse in curse_words)
    has_positive_context = any(re.search(pattern, text_lower) for pattern in positive_context_patterns)
    
    return has_curse_word and has_positive_context

def detect_respeito_boyceta(text):
    """Detecta padr√µes de respeito com 'boyceta'"""
    text_lower = text.lower()
    
    # Padr√µes de respeito com boyceta
    respeito_patterns = [
        r'\b(respeita|respeito|respeitem)\b.*\b(boyceta|boycetas)\b',
        r'\b(boyceta|boycetas)\b.*\b(respeita|respeito|respeitem)\b'
    ]
    
    return any(re.search(pattern, text_lower) for pattern in respeito_patterns)

def detect_hate_emojis_with_laughter(text):
    """Detecta emojis de hate com risadas"""
    # Emojis de hate
    hate_emojis = ['üëø', 'üòà', 'üíÄ', '‚ò†Ô∏è', 'üëª', 'ü§¨', 'üò°', 'üò†']
    
    # Emojis de risada
    laugh_emojis = ['üòÇ', 'ü§£', 'üòÜ', 'üòÑ', 'üòÉ', 'üòä', 'üòã', 'üòú', 'üòù', 'ü§™']
    
    has_hate_emoji = any(emoji in text for emoji in hate_emojis)
    has_laugh_emoji = any(emoji in text for emoji in laugh_emojis)
    
    return has_hate_emoji and has_laugh_emoji

def detect_palhacada_with_laughter(text):
    """Detecta palha√ßada com risadas (hate contra linguagem neutra)"""
    text_lower = text.lower()
    
    # Padr√µes de palha√ßada
    palhacada_patterns = [
        r'\b(palha√ßada|palhacada|palha√ßade)\b',
        r'\b(pare de|para de|chega de)\b.*\b(palha√ßada|palhacada|palha√ßade)\b'
    ]
    
    # Emojis de risada
    laugh_emojis = ['üòÇ', 'ü§£', 'üòÜ', 'üòÑ', 'üòÉ', 'üòä', 'üòã', 'üòú', 'üòù', 'ü§™']
    laugh_text = ['kkkk', 'haha', 'hehe', 'rsrs']
    
    has_palhacada = any(re.search(pattern, text_lower) for pattern in palhacada_patterns)
    has_laugh = any(emoji in text for emoji in laugh_emojis) or any(laugh in text_lower for laugh in laugh_text)
    
    return has_palhacada and has_laugh

def detect_ciphered_curse_words(text):
    """Detecta palavr√µes cifrados com n√∫meros"""
    text_lower = text.lower()
    
    # Padr√µes de palavr√µes cifrados
    ciphered_patterns = [
        r'\bp0rr4\b', r'\bcar4lh0\b', r'\bm3rd4\b', r'\bb0st4\b',
        r'\bput4\b', r'\bf0d4\b', r'\bvi4d0\b', r'\bb1ch4\b'
    ]
    
    return any(re.search(pattern, text_lower) for pattern in ciphered_patterns)

def detect_pathologizing_with_laughter(text):
    """Detecta termos patologizantes com risadas"""
    text_lower = text.lower()
    
    # Termos patologizantes
    pathologizing_terms = [
        r'\b(laudo|diagn√≥stico|psiqui√°trico|psicol√≥gico|mental)\b',
        r'\b(doente|doen√ßa|tratamento|cura|terapia)\b',
        r'\b(dist√∫rbio|s√≠ndrome|transtorno|patologia)\b'
    ]
    
    # Emojis de risada
    laugh_emojis = ['üòÇ', 'ü§£', 'üòÜ', 'üòÑ', 'üòÉ', 'üòä', 'üòã', 'üòú', 'üòù', 'ü§™']
    laugh_text = ['kkkk', 'haha', 'hehe', 'rsrs']
    
    has_pathologizing = any(re.search(pattern, text_lower) for pattern in pathologizing_terms)
    has_laugh = any(emoji in text for emoji in laugh_emojis) or any(laugh in text_lower for laugh in laugh_text)
    
    return has_pathologizing and has_laugh

def detect_positive_emojis_only(text):
    """Detecta apenas emojis positivos (n√£o s√£o hate)"""
    # Emojis positivos
    positive_emojis = ['üòç', 'ü•∞', 'üòò', 'üòó', 'üòô', 'üòö', 'üò∏', 'üòπ', 'üò∫', 'üòª', 'üòº', 'üòΩ', 'üôÄ', 'üòø', 'üòæ', '‚ù§Ô∏è', 'üíñ', 'üíï', 'üíó', 'üíù', 'üíò', 'üíû', 'üíü', '‚ô•Ô∏è', 'üíú', 'üíô', 'üíö', 'üíõ', 'üß°', 'ü§ç', 'üñ§', 'ü§é', 'üíØ', '‚ú®', 'üåü', '‚≠ê', 'üí´', 'üåà', 'ü¶Ñ', 'üëè', 'üôå', 'üëç', 'üëå', 'ü§ù', 'ü§ó', 'ü§≤', 'üôè', 'üí™', 'üéâ', 'üéä', 'üéà', 'üéÅ', 'üèÜ', 'ü•á']
    
    # Verificar se o texto √© apenas emojis positivos
    text_stripped = text.strip()
    
    # Se √© apenas emojis positivos
    if all(char in positive_emojis or char.isspace() for char in text_stripped):
        return True
    
    return False

def detect_positive_context_with_punctuation(text):
    """Detecta contexto positivo com pontua√ß√£o excessiva"""
    text_lower = text.lower()
    
    # Padr√µes de contexto positivo
    positive_patterns = [
        r'\b(meu amor|minha amor|amor)\b',
        r'\b(seja o que voc√™ quiser|seja feliz|feliz sempre)\b',
        r'\b(amo|adoro|gosto|aprecio|respeito|apoio|defendo)\b',
        r'\b(orgulho|pride|diversidade|inclus√£o|igualdade)\b',
        r'\b(conforto|tranquilidade|paz|alegria|felicidade)\b'
    ]
    
    # Verificar se h√° padr√µes positivos
    has_positive_pattern = any(re.search(pattern, text_lower) for pattern in positive_patterns)
    
    # Verificar se h√° pontua√ß√£o excessiva
    has_excessive_punctuation = bool(re.search(r'[!?]{3,}', text))
    
    return has_positive_pattern and has_excessive_punctuation

def detect_mocking_laughter_with_offensive_terms(text):
    """Detecta risadas de deboche com termos ofensivos - VERS√ÉO MELHORADA"""
    text_lower = text.lower()
    
    # Termos ofensivos
    offensive_terms = [
        r'\b(viado|bicha|sapat√£o|paneleiro|gay|l√©sbica|bissexual|queer)\b',
        r'\b(travesti|trans|transg√™nero|transgenero)\b',
        r'\b(nojento|nojenta|escroto|escrota|desgra√ßado|desgra√ßada)\b',
        r'\b(doente|doen√ßa|tratamento|cura|psicol√≥gico|mental)\b',
        r'\b(pecado|deus|dem√¥nio|igreja|b√≠blia|crist√£o)\b',
        r'\b(natural|normal|anormal|aberra√ß√£o|erro)\b'
    ]
    
    # Emojis de risada (m√∫ltiplos indicam deboche)
    laugh_emojis = ['üòÇ', 'ü§£', 'üòÜ', 'üòÑ', 'üòÉ', 'üòä', 'üòã', 'üòú', 'üòù', 'ü§™']
    laugh_text = ['kkkk', 'haha', 'hehe', 'rsrs']
    
    # Contar emojis de risada
    laugh_emoji_count = sum(1 for emoji in laugh_emojis if emoji in text)
    laugh_text_count = sum(1 for laugh in laugh_text if laugh in text_lower)
    
    # Verificar se h√° termos ofensivos
    has_offensive_terms = any(re.search(pattern, text_lower) for pattern in offensive_terms)
    
    # S√≥ √© hate se h√° termos ofensivos E risada
    if not has_offensive_terms:
        return False
    
    # Verificar se h√° risadas m√∫ltiplas (deboche)
    has_mocking_laughter = laugh_emoji_count >= 2 or laugh_text_count >= 1
    
    return has_offensive_terms and has_mocking_laughter

def predict_hate_speech(text):
    """Predi√ß√£o usando regras contextuais + modelo real treinado"""
    try:
        # 0. PRIMEIRO: Verificar casos que devem ser SEMPRE N√ÉO-HATE (ALTA PRIORIDADE)
        
        # Contexto positivo com emojis de apoio
        if detect_positive_context_with_emojis(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'positive_context_with_emojis_rule'
            }
        
        # Padr√µes de orgulho LGBTQIA+
        if detect_orgulho_lgbtqia(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'orgulho_lgbtqia_rule'
            }
        
        # Padr√µes de respeito e aceita√ß√£o
        if detect_respeito_aceitacao(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'respeito_aceitacao_rule'
            }
        
        # Palavr√µes em contexto positivo
        if detect_curse_words_positive_context(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'curse_words_positive_context_rule'
            }
        
        # Linguagem neutra sozinha (N√ÉO √© hate)
        if detect_neutral_language_only(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'neutral_language_only_rule'
            }
        
        # Emoji sozinho ou com contexto m√≠nimo
        if detect_single_emoji_context(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'single_emoji_context_rule'
            }
        
        # Respeito com boyceta
        if detect_respeito_boyceta(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'respeito_boyceta_rule'
            }
        
        # Apenas emojis positivos
        if detect_positive_emojis_only(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'positive_emojis_only_rule'
            }
        
        # Contexto positivo com pontua√ß√£o excessiva
        if detect_positive_context_with_punctuation(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'positive_context_with_punctuation_rule'
            }
        
        # 1. SEGUNDO: Verificar casos que devem ser SEMPRE HATE (ALTA PRIORIDADE)
        
        # Risadas de deboche com termos ofensivos
        if detect_mocking_laughter_with_offensive_terms(text):
            return {
                'is_hate': True,
                'hate_probability': 0.95,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.95,
                'method': 'mocking_laughter_with_offensive_terms_rule'
            }
        
        # Emojis de hate com risadas
        if detect_hate_emojis_with_laughter(text):
            return {
                'is_hate': True,
                'hate_probability': 0.95,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.95,
                'method': 'hate_emojis_with_laughter_rule'
            }
        
        # Palha√ßada com risadas (hate contra linguagem neutra)
        if detect_palhacada_with_laughter(text):
            return {
                'is_hate': True,
                'hate_probability': 0.95,
                'specialized_class': "Transfobia",
                'confidence': 0.95,
                'method': 'palhacada_with_laughter_rule'
            }
        
        # Palavr√µes cifrados
        if detect_ciphered_curse_words(text):
            return {
                'is_hate': True,
                'hate_probability': 0.95,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.95,
                'method': 'ciphered_curse_words_rule'
            }
        
        # Termos patologizantes com risadas
        if detect_pathologizing_with_laughter(text):
            return {
                'is_hate': True,
                'hate_probability': 0.95,
                'specialized_class': "Transfobia",
                'confidence': 0.95,
                'method': 'pathologizing_with_laughter_rule'
            }
        
        # 2. TERCEIRO: Verificar machismo atrav√©s de genitais masculinos (ALTA PRIORIDADE)
        
        if detect_enhanced_male_genital_machismo(text):
            return {
                'is_hate': True,
                'hate_probability': 0.95,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.95,
                'method': 'enhanced_male_genital_machismo_rule'
            }
        
        # 1. SEGUNDO: Verificar √≥dio contra linguagem neutra (ALTA PRIORIDADE)
        
        if detect_enhanced_neutral_language_hate(text):
            return {
                'is_hate': True,
                'hate_probability': 0.95,
                'specialized_class': "Transfobia",
                'confidence': 0.95,
                'method': 'enhanced_neutral_language_hate_rule'
            }
        
        # 2. TERCEIRO: Verificar casos que devem ser N√ÉO-HATE (alta prioridade para reduzir falsos positivos)
        
        if detect_care_expressions(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'care_expressions_rule'
            }
        
        if detect_neutral_curse_words(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'neutral_curse_words_rule'
            }
        
        if detect_disapproval_without_hate(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'disapproval_without_hate_rule'
            }
        
        if detect_generic_insults_without_context(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'generic_insults_without_context_rule'
            }
        
        if detect_neutral_emoji_context(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'neutral_emoji_context_rule'
            }
        
        if detect_neutral_language_specific_cases(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'neutral_language_specific_cases_rule'
            }
        
        # 1. SEGUNDO: Verificar casos espec√≠ficos problem√°ticos identificados pelo usu√°rio
        
        # Casos que devem ser HATE
        if detect_generation_expressions(text):
            return {
                'is_hate': True,
                'hate_probability': 0.95,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.95,
                'method': 'generation_expressions_rule'
            }
        
        if detect_male_genital_machismo(text):
            return {
                'is_hate': True,
                'hate_probability': 0.90,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.90,
                'method': 'male_genital_machismo_rule'
            }
        
        # Emoji de palha√ßo isolado pode ser neutro ou hate dependendo do contexto
        # Se for apenas o emoji, considerar como n√£o-hate
        if text.strip() == 'ü§°':
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'clown_emoji_isolated_neutral_rule'
            }
        
        if detect_neutral_language_opposition(text):
            return {
                'is_hate': True,
                'hate_probability': 0.95,
                'specialized_class': "Transfobia",
                'confidence': 0.95,
                'method': 'neutral_language_opposition_rule'
            }
        
        if detect_clown_emoji_context(text):
            return {
                'is_hate': True,
                'hate_probability': 0.90,
                'specialized_class': "Transfobia", 
                'confidence': 0.90,
                'method': 'clown_emoji_context_rule'
            }
        
        if detect_vomit_emoji_context(text):
            return {
                'is_hate': True,
                'hate_probability': 0.95,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.95,
                'method': 'vomit_emoji_context_rule'
            }
        
        # Casos que devem ser N√ÉO-HATE
        if detect_laughter_context_neutral(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'laughter_context_neutral_rule'
            }
        
        if detect_curse_words_neutral_context(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'curse_words_neutral_context_rule'
            }
        
        if detect_tiredness_expressions(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'tiredness_expressions_rule'
            }
        
        if detect_religious_neutral_expressions(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'religious_neutral_expressions_rule'
            }
        
        # 1. SEGUNDO: Verificar emojis de hate (sempre hate)
        # Esta tem prioridade m√°xima para detectar √≥dio expl√≠cito
        if detect_hate_emojis(text):
            return {
                'is_hate': True,
                'hate_probability': 0.95,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.95,
                'method': 'hate_emoji_rule'
            }
        
        # 2. SEGUNDO: Verificar emojis de apoio (n√£o √© hate)
        # Esta tem prioridade alta para proteger apoio leg√≠timo
        if detect_supportive_emojis(text):
            return {
                'is_hate': False,
                'hate_probability': 0.01,
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'supportive_emoji_rule'
            }
        
        # 3. TERCEIRO: Verificar emojis de deboche (poss√≠vel hate)
        if detect_mocking_emojis(text) or detect_text_mocking_patterns(text):
            return {
                'is_hate': True,
                'hate_probability': 0.90,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.90,
                'method': 'mocking_emoji_rule'
            }
        
        # 4. QUARTO: Verificar comandos condescendentes (geralmente hate)
        if detect_condescending_commands(text):
            return {
                'is_hate': True,
                'hate_probability': 0.85,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.85,
                'method': 'condescending_command_rule'
            }
        
        # 5. QUINTO: Verificar moralismo religioso (geralmente hate)
        if detect_religious_moralism(text):
            return {
                'is_hate': True,
                'hate_probability': 0.80,
                'specialized_class': "Transfobia",
                'confidence': 0.80,
                'method': 'religious_moralism_rule'
            }
        
        # 6. SEXTO: Verificar termos patologizantes (geralmente hate)
        if detect_pathologizing_terms(text):
            return {
                'is_hate': True,
                'hate_probability': 0.85,
                'specialized_class': "Transfobia",
                'confidence': 0.85,
                'method': 'pathologizing_terms_rule'
            }
        
        # 7. S√âTIMO: Verificar hate disfar√ßado (geralmente hate)
        if detect_disguised_hate(text):
            return {
                'is_hate': True,
                'hate_probability': 0.90,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.90,
                'method': 'disguised_hate_rule'
            }
        
        # 8. OITAVO: Verificar termos de vergonha (geralmente hate)
        if detect_shame_terms(text):
            return {
                'is_hate': True,
                'hate_probability': 0.80,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.80,
                'method': 'shame_terms_rule'
            }
        
        # 9. NONO: Verificar palavr√µes (geralmente hate)
        if detect_curse_words(text):
            return {
                'is_hate': True,
                'hate_probability': 0.90,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.90,
                'method': 'curse_words_rule'
            }
        
        # 10. D√âCIMO: Verificar termos machistas (geralmente hate)
        if detect_misogynistic_terms(text):
            return {
                'is_hate': True,
                'hate_probability': 0.85,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.85,
                'method': 'misogynistic_terms_rule'
            }
        
        # 11. D√âCIMO PRIMEIRO: Verificar met√°foras condescendentes (geralmente hate)
        if detect_condescending_metaphors(text):
            return {
                'is_hate': True,
                'hate_probability': 0.80,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.80,
                'method': 'condescending_metaphors_rule'
            }
        
        # 12. D√âCIMO SEGUNDO: Verificar insultos condescendentes (geralmente hate)
        if detect_condescending_insults(text):
            return {
                'is_hate': True,
                'hate_probability': 0.85,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.85,
                'method': 'condescending_insults_rule'
            }
        
        # 13. D√âCIMO TERCEIRO: Verificar excessos de pontua√ß√£o (geralmente hate)
        if detect_excessive_punctuation(text):
            return {
                'is_hate': True,
                'hate_probability': 0.75,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.75,
                'method': 'excessive_punctuation_rule'
            }
        
        # 14. D√âCIMO QUARTO: Verificar insultos diretos (geralmente hate)
        if detect_direct_insults(text):
            return {
                'is_hate': True,
                'hate_probability': 0.90,
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.90,
                'method': 'direct_insults_rule'
            }
        
        # 4. QUARTO: Aplicar regras contextuais para termos de g√™nero
        contextual_result = enhanced_hybrid_rules(text)
        
        if contextual_result == "n√£o_hate":
            return {
                'is_hate': False,
                'hate_probability': 0.01,  # Muito baixa para n√£o-hate
                'specialized_class': "N/A",
                'confidence': 0.99,
                'method': 'contextual_rule_positive'
            }
        elif contextual_result == "hate":
            return {
                'is_hate': True,
                'hate_probability': 0.95,  # Alta para hate contextual
                'specialized_class': "Transfobia",  # Assumir transfobia para termos de g√™nero
                'confidence': 0.95,
                'method': 'contextual_rule_negative'
            }
        elif contextual_result == "assedio_insulto":
            return {
                'is_hate': True,
                'hate_probability': 0.95,  # Alta para hate contextual
                'specialized_class': "Ass√©dio/Insulto",
                'confidence': 0.95,
                'method': 'contextual_rule_insult'
            }
        
        # 2. SEGUNDO: Se n√£o h√° regra contextual, usar modelo normal
        # Normalizar texto
        normalized_text = normalize_text(text)
        
        # Tokenizar
        inputs = tokenizer_binary(normalized_text, return_tensors="pt", padding=True, truncation=True, max_length=512)
        
        # Predi√ß√£o bin√°ria
        with torch.no_grad():
            outputs_binary = model_binary(**inputs)
            binary_probs = torch.softmax(outputs_binary.logits, dim=-1)
            hate_probability = binary_probs[0][1].item()
        
        # Threshold otimizado baseado nos testes
        THRESHOLD = 0.05  # Reduzido de 0.15 para 0.05
        
        # Verificar se √© um falso positivo potencial
        if (hate_probability >= THRESHOLD and 
            is_lgbtqia_pattern(text) and 
            has_positive_adjective(text)):
            
            # Reduzir drasticamente a probabilidade para adjetivos positivos
            hate_probability = 0.01  # 1% - praticamente N√ÉO-HATE
        
        is_hate = hate_probability >= THRESHOLD
        
        # Se √© hate, fazer predi√ß√£o especializada
        if is_hate:
            inputs_specialized = tokenizer_specialized(normalized_text, return_tensors="pt", padding=True, truncation=True, max_length=512)
            with torch.no_grad():
                outputs_specialized = model_specialized(**inputs_specialized)
                specialized_probs = torch.softmax(outputs_specialized.logits, dim=-1)
                specialized_pred = torch.argmax(specialized_probs, dim=-1)
            
            # Mapear classes especializadas
            class_mapping = {0: "Transfobia", 1: "Ass√©dio/Insulto"}
            specialized_class = class_mapping.get(specialized_pred.item(), "Ass√©dio/Insulto")
        else:
            specialized_class = "N/A"
        
        confidence = max(hate_probability, 1-hate_probability)
        
        return {
            'is_hate': is_hate,
            'hate_probability': hate_probability,
            'specialized_class': specialized_class,
            'confidence': confidence,
            'method': 'model_prediction'
        }
        
    except Exception as e:
        print(f"Erro na predi√ß√£o: {e}")
        return simulate_hate_detection(text)

# --- Fun√ß√µes de An√°lise ---
def analyze_single_text(text):
    """Analisa um √∫nico texto"""
    if not text or not text.strip():
        return "‚ùå Por favor, insira um texto para an√°lise."
    
    result = predict_hate_speech(text)
    
    # Emoji baseado no resultado
    if result['is_hate']:
        emoji = "üî¥"
        status = "HATE SPEECH DETECTADO"
        color = "#ff4444"
    else:
        emoji = "üü¢"
        status = "N√ÉO √â HATE SPEECH"
        color = "#44ff44"
    
    # Informa√ß√µes detalhadas
    details = f"""
    <div style="background-color: {color}20; padding: 15px; border-radius: 10px; margin: 10px 0;">
        <h3 style="color: {color}; margin-top: 0;">{emoji} {status}</h3>
        <p><strong>Probabilidade de Hate:</strong> {result['hate_probability']:.1%}</p>
        <p><strong>Classe Especializada:</strong> {result['specialized_class']}</p>
        <p><strong>Confian√ßa:</strong> {result['confidence']:.1%}</p>
        <p><strong>M√©todo:</strong> {result.get('method', 'model_prediction')}</p>
    </div>
    """
    
    return details

def analyze_batch_text(texts):
    """Analisa m√∫ltiplos textos"""
    if not texts or not texts.strip():
        return "‚ùå Por favor, insira textos para an√°lise."
    
    # Separar textos por linha
    text_list = [line.strip() for line in texts.split('\n') if line.strip()]
    
    if not text_list:
        return "‚ùå Nenhum texto v√°lido encontrado."
    
    results = []
    hate_count = 0
    
    for i, text in enumerate(text_list, 1):
        result = predict_hate_speech(text)
        
        if result['is_hate']:
            emoji = "üî¥"
            status = "HATE"
            hate_count += 1
        else:
            emoji = "üü¢"
            status = "N√ÉO-HATE"
        
        results.append(f"{emoji} <strong>{i}.</strong> {status} ({result['hate_probability']:.1%}) - {text}")
    
    summary = f"""
    <div style="background-color: #f0f0f0; padding: 15px; border-radius: 10px; margin: 10px 0;">
        <h3>üìä Resumo da An√°lise</h3>
        <p><strong>Total de textos:</strong> {len(text_list)}</p>
        <p><strong>Hate speech detectado:</strong> {hate_count}</p>
        <p><strong>Taxa de detec√ß√£o:</strong> {hate_count/len(text_list):.1%}</p>
    </div>
    """
    
    return summary + "<br>".join(results)

# --- Interface Gradio ---
with gr.Blocks(
    title="Radar Social LGBTQIA+",
    theme=gr.themes.Soft(),
    css="""
    .main-header {
        text-align: center;
        background: linear-gradient(90deg, #ff6b6b, #4ecdc4);
        color: white;
        padding: 20px;
        border-radius: 10px;
        margin-bottom: 20px;
    }
    .analysis-box {
        background-color: #f8f9fa;
        padding: 15px;
        border-radius: 10px;
        border-left: 5px solid #007bff;
        margin: 10px 0;
    }
    """
) as interface:
    
    gr.HTML("""
    <div class="main-header">
        <h1>üè≥Ô∏è‚Äçüåà Radar Social LGBTQIA+</h1>
        <p>Sistema de Intelig√™ncia Artificial (AI) com Processamento de Linguagem Natural (PLN) e Machine Learning (ML)</p>
        <p>Detec√ß√£o avan√ßada de hate speech com regras contextuais e prote√ß√£o de termos de dissid√™ncia de g√™nero</p>
    </div>
    """)
    
    # Informa√ß√µes principais antes das abas
    gr.Markdown("""
    ## üéØ Funcionalidades
    
    - **ü§ñ Intelig√™ncia Artificial (AI)**: Sistema automatizado de detec√ß√£o de hate speech
    - **üß† Processamento de Linguagem Natural (PLN)**: An√°lise contextual de texto em portugu√™s brasileiro
    - **üìä Machine Learning (ML)**: Modelos BERTimbau fine-tuned com ensemble learning
    - **üîç Regras Contextuais**: Prote√ß√£o inteligente de termos de dissid√™ncia de g√™nero
    - **‚ö° An√°lise Especializada**: Classifica√ß√£o entre Transfobia e Ass√©dio/Insulto
    
    ## üîß Tecnologia
    
    - **üèóÔ∏è Arquitetura**: Sistema Ensemble (Bin√°rio + Especializado)
    - **üß† Modelo Base**: BERTimbau (BERT em portugu√™s brasileiro)
    - **üìà Threshold Adaptativo**: Otimiza√ß√£o din√¢mica baseada em contexto
    - **üîÑ Pipeline NLP**: Normaliza√ß√£o, tokeniza√ß√£o e an√°lise sem√¢ntica
    - **üéØ Regras H√≠bridas**: Combina√ß√£o de ML e regras espec√≠ficas
    
    ## üìä M√©tricas
    
    - **üéØ Accuracy**: 74.6% (2.053 exemplos testados)
    - **‚ö° Precision**: 44.5% | **üìà Recall**: 86.0% | **üéØ F1-Score**: 58.6%
    - **üîß Regras Contextuais**: 100% accuracy nos casos problem√°ticos
    - **üìä Processamento**: 2.6% casos com regras contextuais, 97.4% com modelo ML
    """)
    
    with gr.Tabs():
        with gr.TabItem("üîç An√°lise Individual"):
            gr.Markdown("### Analise um texto espec√≠fico")
            
            text_input = gr.Textbox(
                label="Digite o texto para an√°lise",
                placeholder="Ex: 'Orgulho de ser boyceta' ou 'Viado do caralho'",
                lines=3
            )
            
            analyze_btn = gr.Button("üîç Analisar", variant="primary")
            
            result_output = gr.HTML(label="Resultado da An√°lise")
            
            analyze_btn.click(
                fn=analyze_single_text,
                inputs=text_input,
                outputs=result_output
            )
        
        with gr.TabItem("üìä An√°lise em Lote"):
            gr.Markdown("### Analise m√∫ltiplos textos (um por linha)")
            
            batch_input = gr.Textbox(
                label="Digite os textos para an√°lise (um por linha)",
                placeholder="Ex:\nOrgulho de ser boyceta\nViado do caralho\nSapat√£o √© for√ßa",
                lines=10
            )
            
            batch_analyze_btn = gr.Button("üìä Analisar Lote", variant="primary")
            
            batch_result_output = gr.HTML(label="Resultado da An√°lise em Lote")
            
            batch_analyze_btn.click(
                fn=analyze_batch_text,
                inputs=batch_input,
                outputs=batch_result_output
            )
        
        with gr.TabItem("‚ÑπÔ∏è Informa√ß√µes T√©cnicas"):
            gr.Markdown("""
            ## üéØ Regras Contextuais
            
            ### üõ°Ô∏è Prote√ß√£o de Termos de G√™nero
            - **"boyceta"**: Detecta contexto positivo vs negativo
            - **"sapat√£o"**: Protege identidade l√©sbica
            - **"travesti"**: Respeita identidade trans
            - **"transg√™nero"**: An√°lise contextual de identidade
            
            ### üîç Contextos Detectados
            - **‚úÖ Positivo**: orgulho, beleza, identidade, express√£o
            - **‚ùå Negativo**: nojo, escroto, desgra√ßado, arrombado
            - **üìö Educativo**: defini√ß√£o, conceito, explica√ß√£o
            - **üòÑ Ridiculariza√ß√£o**: engra√ßado, hil√°rio, c√¥mico
            
            ### üß† Arquitetura do Sistema
            
            #### ü§ñ Modelos de Machine Learning
            - **Modelo Bin√°rio**: Detecta hate vs n√£o-hate (BERTimbau)
            - **Modelo Especializado**: Classifica tipo de hate (2 classes)
            - **Ensemble Learning**: Combina√ß√£o de m√∫ltiplos modelos
            - **Fine-tuning**: Adapta√ß√£o espec√≠fica para portugu√™s brasileiro
            
            #### üîÑ Pipeline de Processamento
            1. **Normaliza√ß√£o**: URLs, men√ß√µes e hashtags substitu√≠das
            2. **Tokeniza√ß√£o**: Convers√£o para tokens num√©ricos
            3. **An√°lise Contextual**: Aplica√ß√£o de regras espec√≠ficas
            4. **Classifica√ß√£o ML**: Predi√ß√£o com modelos treinados
            5. **P√≥s-processamento**: Ajustes baseados em contexto
            
            ### üìä Base de Dados
            
            #### üóÉÔ∏è Fontes Integradas
            - **Anota√ß√µes Manuais**: Equipe C√≥digo N√£o Bin√°rio
            - **Dataset ToLD-BR**: Dados acad√™micos em portugu√™s
            - **Dataset Anti-LGBT**: Cyberbullying traduzido para PT-BR
            - **Dados Reais**: Instagram do podcast Entre Amigues
            
            #### üìà Estat√≠sticas
            - **Total de exemplos**: ~15.000 coment√°rios
            - **Dataset expandido**: 4.780.095 exemplos
            - **Valida√ß√£o**: Testado com dados reais de hate speech
            - **Anonimiza√ß√£o**: Dados pessoais removidos para privacidade
            
            ### ‚ö†Ô∏è Considera√ß√µes √âticas
            
            #### üîí Privacidade e Conformidade
            - **LGPD/GDPR**: Compat√≠vel com regulamenta√ß√µes de privacidade
            - **Anonimiza√ß√£o**: IDs substitu√≠dos por hashes
            - **Normaliza√ß√£o**: Men√ß√µes (@usuario) e URLs removidas
            - **Transpar√™ncia**: Metodologia aberta e audit√°vel
            
            #### üéØ Uso Respons√°vel
            - **Foco Social**: Combate ao discurso de √≥dio LGBTQIA+
            - **Prote√ß√£o**: Termos de identidade de g√™nero respeitados
            - **Educa√ß√£o**: Ferramenta de apoio para modera√ß√£o
            - **Impacto**: Baseado em dados reais de √≥dio sofrido
            
            ### üîó Links e Recursos
            
            #### üìö Projetos Relacionados
            - [Modelo no Hugging Face](https://hf.co/Veronyka/radar-social-lgbtqia)
            - [Dataset no Hugging Face](https://hf.co/datasets/Veronyka/base-dados-odio-lgbtqia)
            - [Reposit√≥rio GitHub (Modelo)](https://github.com/travahacker/radar-social-lgbtqia)
            - [Reposit√≥rio GitHub (Dataset)](https://github.com/travahacker/base-dados-odio-lgbtqia)
            
            #### üè≥Ô∏è‚Äçüåà C√≥digo N√£o Bin√°rio
            - [Site Oficial](https://codigonaobinario.org)
            - [Podcast Entre Amigues](https://linktr.ee/entre_amigues)
            
            ---
            
            **Desenvolvido com ‚ù§Ô∏è pela equipe C√≥digo N√£o Bin√°rio**
            """)
    

if __name__ == "__main__":
    interface.launch()
