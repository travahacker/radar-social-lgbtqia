#!/usr/bin/env python3
"""
An√°lise final do dataset com regras melhoradas
"""

import pandas as pd
import numpy as np
from datetime import datetime
import sys
import os

# Adicionar o diret√≥rio atual ao path para importar app
sys.path.append('.')

def load_original_dataset():
    """Carrega o dataset original com r√≥tulos corretos"""
    print("üìÇ Carregando dataset original...")
    
    # Carregar dataset original (pular primeira linha que n√£o √© cabe√ßalho)
    df_original = pd.read_csv(
        'clean-annotated-data/export_1757023553205_limpa.csv',
        sep=';',
        encoding='utf-8'
    )
    
    print(f"‚úÖ Dataset original carregado: {len(df_original)} exemplos")
    return df_original

def convert_labels_correctly(df_original):
    """Converte r√≥tulos do dataset original para formato bin√°rio correto"""
    print("üîÑ Convertendo r√≥tulos corretamente...")
    
    # Para o dataset limpo, n√£o temos r√≥tulos de hate, ent√£o vamos usar o sistema para gerar
    # Criar dataset final
    df_final = df_original[['id', 'Comment Text']].copy()
    df_final.columns = ['id', 'text']
    
    # Adicionar coluna is_hate como None (ser√° preenchida pelo sistema)
    df_final['is_hate'] = None
    
    # Remover linhas com texto vazio ou NaN
    df_final = df_final.dropna(subset=['text'])
    df_final = df_final[df_final['text'].str.strip() != '']
    
    print(f"‚úÖ Dataset final corrigido: {len(df_final)} exemplos")
    print(f"üìä Distribui√ß√£o: {df_final['is_hate'].value_counts().to_dict()}")
    
    return df_final

def analyze_with_improved_system(df_final):
    """Analisa o dataset com o sistema melhorado"""
    print("ü§ñ Analisando com sistema melhorado...")
    
    try:
        # Importar sistema atual do Space
        from app_space_version import predict_hate_speech
        
        results = []
        correct_predictions = 0
        total_predictions = 0
        
        for idx, row in df_final.iterrows():
            text = row['text']
            
            try:
                # Predi√ß√£o do sistema
                prediction = predict_hate_speech(text)
                predicted_hate = prediction['is_hate']
                
                # An√°lise de caracter√≠sticas do texto
                text_length = len(text)
                has_emoji = any(ord(char) > 127 for char in text)  # Detec√ß√£o simples de emoji
                has_punctuation = any(p in text for p in ['!', '?', '.', ',', ';', ':'])
                has_caps = any(c.isupper() for c in text)
                
                total_predictions += 1
                
                results.append({
                    'id': row['id'],
                    'text': text,
                    'text_length': text_length,
                    'has_emoji': has_emoji,
                    'has_punctuation': has_punctuation,
                    'has_caps': has_caps,
                    'predicted_label': 'HATE' if predicted_hate else 'N√ÉO-HATE',
                    'method': prediction.get('method', 'unknown'),
                    'specialized_class': prediction.get('specialized_class', 'N/A'),
                    'confidence': prediction.get('confidence', 0.0),
                    'hate_probability': prediction.get('hate_probability', 0.0)
                })
                
                if idx % 100 == 0:
                    print(f"üìä Processados: {idx}/{len(df_final)} ({idx/len(df_final)*100:.1f}%)")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao processar linha {idx}: {e}")
                continue
        
        # Contar hate vs n√£o-hate
        hate_count = sum(1 for r in results if r['predicted_label'] == 'HATE')
        non_hate_count = total_predictions - hate_count
        
        print(f"‚úÖ An√°lise conclu√≠da: {total_predictions} exemplos processados")
        print(f"üìä Distribui√ß√£o: {hate_count} HATE, {non_hate_count} N√ÉO-HATE ({hate_count/total_predictions*100:.1f}% hate)")
        
        return results, hate_count/total_predictions
        
    except ImportError as e:
        print(f"‚ùå Erro ao importar sistema: {e}")
        return [], 0.0

def generate_final_reports(results, hate_percentage):
    """Gera relat√≥rios finais em CSV"""
    print("üìä Gerando relat√≥rios finais...")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Converter para DataFrame
    df_results = pd.DataFrame(results)
    
    if len(df_results) == 0:
        print("‚ùå Nenhum resultado para gerar relat√≥rios")
        return
    
    # 1. An√°lise completa
    analysis_file = f"out/analise_dataset_completa_{timestamp}.csv"
    df_results.to_csv(analysis_file, index=False, encoding='utf-8')
    print(f"üìÑ An√°lise completa: {analysis_file}")
    
    # 2. Casos de hate detectados
    hate_cases = df_results[df_results['predicted_label'] == 'HATE']
    hate_file = f"out/casos_hate_detectados_{timestamp}.csv"
    hate_cases.to_csv(hate_file, index=False, encoding='utf-8')
    print(f"üìÑ Casos de hate: {hate_file} ({len(hate_cases)} casos)")
    
    # 3. Resumo da an√°lise
    summary_data = {
        'metric': ['Total de exemplos', 'Hate detectado', 'N√£o-hate', 'Percentual hate', 'Confian√ßa m√©dia'],
        'value': [
            len(df_results),
            len(hate_cases),
            len(df_results) - len(hate_cases),
            f"{hate_percentage:.1%}",
            f"{df_results['confidence'].mean():.3f}"
        ]
    }
    
    summary_df = pd.DataFrame(summary_data)
    summary_file = f"out/resumo_analise_{timestamp}.csv"
    summary_df.to_csv(summary_file, index=False, encoding='utf-8')
    print(f"üìÑ Resumo da an√°lise: {summary_file}")
    
    # 4. An√°lise por m√©todo
    method_analysis = df_results.groupby('method').agg({
        'predicted_label': 'count',
        'confidence': 'mean',
        'hate_probability': 'mean'
    }).round(3)
    
    method_analysis.columns = ['total', 'avg_confidence', 'avg_hate_prob']
    method_analysis = method_analysis.reset_index()
    
    method_file = f"out/analise_por_metodo_{timestamp}.csv"
    method_analysis.to_csv(method_file, index=False, encoding='utf-8')
    print(f"üìÑ An√°lise por m√©todo: {method_file}")
    
    # 5. An√°lise por classe especializada
    specialized_analysis = df_results[df_results['specialized_class'] != 'N/A'].groupby('specialized_class').agg({
        'predicted_label': 'count',
        'confidence': 'mean',
        'hate_probability': 'mean'
    }).round(3)
    
    specialized_analysis.columns = ['total', 'avg_confidence', 'avg_hate_prob']
    specialized_analysis = specialized_analysis.reset_index()
    
    specialized_file = f"out/analise_por_classe_{timestamp}.csv"
    specialized_analysis.to_csv(specialized_file, index=False, encoding='utf-8')
    print(f"üìÑ An√°lise por classe: {specialized_file}")
    
    return {
        'analysis_file': analysis_file,
        'hate_file': hate_file,
        'summary_file': summary_file,
        'method_file': method_file,
        'specialized_file': specialized_file
    }

def main():
    """Fun√ß√£o principal"""
    print("üöÄ AN√ÅLISE FINAL COM REGRAS MELHORADAS")
    print("=" * 60)
    
    try:
        # 1. Carregar dataset original
        df_original = load_original_dataset()
        
        # 2. Converter r√≥tulos corretamente
        df_final = convert_labels_correctly(df_original)
        
        # 3. Analisar com sistema melhorado
        results, hate_percentage = analyze_with_improved_system(df_final)
        
        # 4. Gerar relat√≥rios finais
        if results:
            files = generate_final_reports(results, hate_percentage)
            
            print("\n" + "=" * 60)
            print("‚úÖ AN√ÅLISE FINAL MELHORADA CONCLU√çDA")
            print("=" * 60)
            print(f"üìä Percentual de hate detectado: {hate_percentage:.1%}")
            print(f"üìÑ Arquivos gerados:")
            for key, file in files.items():
                print(f"  ‚Ä¢ {file}")
        else:
            print("‚ùå Falha na an√°lise - nenhum resultado gerado")
            
    except Exception as e:
        print(f"‚ùå Erro na an√°lise: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
